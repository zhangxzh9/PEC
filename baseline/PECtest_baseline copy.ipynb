{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "#env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_path = '/home/ubuntu/data/dataset/R3009_U5_V100/'\n",
    "UIT = pd.read_csv(data_path + 'UIT.csv')\n",
    "UIT"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>viewtime</th>\n",
       "      <th>video_type</th>\n",
       "      <th>video_format</th>\n",
       "      <th>city</th>\n",
       "      <th>city_isp</th>\n",
       "      <th>client_ip</th>\n",
       "      <th>conn_type</th>\n",
       "      <th>device_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365</td>\n",
       "      <td>3391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>1030</td>\n",
       "      <td>101001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11807</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>5779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15068</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208</td>\n",
       "      <td>4675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>1035</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5375</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1030</td>\n",
       "      <td>10202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5992</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>439</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3468</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300978</th>\n",
       "      <td>483</td>\n",
       "      <td>6831</td>\n",
       "      <td>29</td>\n",
       "      <td>2591880</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300979</th>\n",
       "      <td>158</td>\n",
       "      <td>8448</td>\n",
       "      <td>29</td>\n",
       "      <td>2591880</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23340</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300980</th>\n",
       "      <td>483</td>\n",
       "      <td>6463</td>\n",
       "      <td>29</td>\n",
       "      <td>2591940</td>\n",
       "      <td>35</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300981</th>\n",
       "      <td>158</td>\n",
       "      <td>4715</td>\n",
       "      <td>29</td>\n",
       "      <td>2591940</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23340</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300982</th>\n",
       "      <td>483</td>\n",
       "      <td>2021</td>\n",
       "      <td>29</td>\n",
       "      <td>2591940</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300983 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          u     i  day     time  viewtime  video_type  video_format  city  \\\n",
       "0       365  3391    0        0       148        1030        101001     0   \n",
       "1       203  5779    0        0         7        1030         10203     0   \n",
       "2       208  4675    0        0        92        1035         10203     0   \n",
       "3       159   332    0        0        56        1030         10202     0   \n",
       "4        50   674    0        0       439        1030         10203     0   \n",
       "...     ...   ...  ...      ...       ...         ...           ...   ...   \n",
       "300978  483  6831   29  2591880        34        1030         10203     0   \n",
       "300979  158  8448   29  2591880        34        1030         10203     0   \n",
       "300980  483  6463   29  2591940        35        1030         10203     0   \n",
       "300981  158  4715   29  2591940        34        1030         10203     0   \n",
       "300982  483  2021   29  2591940        34        1030         10203     0   \n",
       "\n",
       "        city_isp  client_ip  conn_type  device_type  \n",
       "0              0      11807          1            2  \n",
       "1              0      15068          1            2  \n",
       "2              0       5375          1            2  \n",
       "3              0       5992          1            2  \n",
       "4              0       3468          1            2  \n",
       "...          ...        ...        ...          ...  \n",
       "300978         0      10010          1            2  \n",
       "300979         0      23340          1            2  \n",
       "300980         0      10010          1            2  \n",
       "300981         0      23340          1            2  \n",
       "300982         0      10010          1            2  \n",
       "\n",
       "[300983 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "trainUIT = UIT[UIT['day']<18]\n",
    "contentNum = len(UIT.i.drop_duplicates())\n",
    "userNum = len(UIT.u.drop_duplicates())\n",
    "contentNum,userNum,trainUIT"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000,\n",
       " 500,\n",
       "           u     i  day     time  viewtime  video_type  video_format  city  \\\n",
       " 0       365  3391    0        0       148        1030        101001     0   \n",
       " 1       203  5779    0        0         7        1030         10203     0   \n",
       " 2       208  4675    0        0        92        1035         10203     0   \n",
       " 3       159   332    0        0        56        1030         10202     0   \n",
       " 4        50   674    0        0       439        1030         10203     0   \n",
       " ...     ...   ...  ...      ...       ...         ...           ...   ...   \n",
       " 198170  264  7442   17  1555140        90        1035         10203     0   \n",
       " 198171   19  9362   17  1555140       424        1035         10203     0   \n",
       " 198172   82  9223   17  1555140        94        1037         10203     0   \n",
       " 198173   35  4164   17  1555140        22        1030         10203     0   \n",
       " 198174  239  5062   17  1555140        89        1035         10203     0   \n",
       " \n",
       "         city_isp  client_ip  conn_type  device_type  \n",
       " 0              0      11807          1            2  \n",
       " 1              0      15068          1            2  \n",
       " 2              0       5375          1            2  \n",
       " 3              0       5992          1            2  \n",
       " 4              0       3468          1            2  \n",
       " ...          ...        ...        ...          ...  \n",
       " 198170         0       7592          1            2  \n",
       " 198171         0       5938          1            2  \n",
       " 198172         0      11393          1            2  \n",
       " 198173         0       5866          1            2  \n",
       " 198174         0      23746          1            2  \n",
       " \n",
       " [198175 rows x 12 columns])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class ENV(object):\n",
    "    def __init__(self,userNum,contentNum):\n",
    "        self.userNum = userNum\n",
    "        self.contentNum =contentNum\n",
    "\n",
    "        self.r = np.zeros(shape=(userNum,contentNum),dtype=int)\n",
    "        self.p = np.full(shape=contentNum,fill_value = 1/userNum)\n",
    "        self.e = np.zeros(shape=contentNum)\n",
    "        self.S = np.ones(shape=contentNum,dtype=int)\n",
    "        self.l_edge = 0.1\n",
    "        self.l_cp = 1\n",
    "\n",
    "        self.B = np.full(shape=userNum,fill_value=5,dtype=int)\n",
    "\n",
    "        self.pipe = collections.OrderedDict()\n",
    "\n",
    "\n",
    "    #有序字典实现LRU\n",
    "    def updateEgdeCache(self,action,t):\n",
    "        for i in np.argwhere(action==1).squeeze(-1):\n",
    "            if i in self.pipe.keys():\n",
    "                self.pipe.pop(i)\n",
    "            elif len(self.pipe) >= 500:\n",
    "                self.e[self.pipe.popitem(last=False)[0]] = 0\n",
    "            self.pipe[i] = t\n",
    "            self.e[i] = 1\n",
    "\n",
    "    \n",
    "    def updateEnv(self,u,action,t):\n",
    "        \n",
    "        p_tmp = ((self.r[u] | action)-self.r[u])*(1/self.userNum) + self.p\n",
    "        self.p = np.where(p_tmp<1-1/self.userNum,p_tmp,1-1/self.userNum)\n",
    "\n",
    "        self.r[u] = self.r[u] | action\n",
    "\n",
    "        self.updateEgdeCache(action,t)\n",
    "\n",
    "    def getStatus(self):\n",
    "        return (torch.from_numpy(self.r),\n",
    "                torch.from_numpy(self.p) , \n",
    "                torch.from_numpy(self.e),\n",
    "                torch.from_numpy(self.S),\n",
    "                self.l_edge,\n",
    "                self.l_cp)\n",
    "\n",
    "    #def reset(self):\n",
    "    #    self.r = np.zeros(shape=(self.userNum,self.contentNum),dtype=int)\n",
    "    #    self.p = np.full(shape=self.contentNum,fill_value = 1/self.userNum)\n",
    "    #    self.e = np.zeros(shape=self.contentNum)\n",
    "    #    self.S = np.ones(shape=self.contentNum,dtype=int)\n",
    "    #    self.l_edge = 0.1\n",
    "    #    self.l_cp = 1\n",
    "    #    self.B = np.full(shape=self.userNum,fill_value=15,dtype=int)\n",
    "    #    self.pipe = collections.OrderedDict()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class UE_random(object):\n",
    "    def __init__(self,u,env,rewardPara):\n",
    "        self.u = u\n",
    "\n",
    "        self.W = []\n",
    "        self.v = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "\n",
    "        self.Bu = int(env.B[self.u])\n",
    "        self.contentNum = env.contentNum\n",
    "        self.userNum = env.userNum\n",
    "\n",
    "        self.r , self.p , self.e, self.S,self.l_edge, self.l_cp = env.getStatus()\n",
    "\n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.lastAction = self.action\n",
    "\n",
    "        self.reward = 0\n",
    "        self.ALPHAh = rewardPara['alpha']\n",
    "        self.BETAo =  rewardPara['betao']\n",
    "        self.BETAl =  rewardPara['betal']\n",
    "\n",
    "    def updateViewContent(self,i):\n",
    "        self.W.append(i)\n",
    "        self.v[i] = 1\n",
    "\n",
    "    \n",
    "    def getReward(self,lastru,lastp,ru,p,i,action,S,Bu,l_edge,l_cp,e):\n",
    "\n",
    "        self.Rh = - self.ALPHAh * (torch.log(ru * p + (1-ru) * (1-p)) - torch.log(lastru * lastp + (1-lastru) * (1-lastp))).sum()\n",
    "\n",
    "        self.Ro =   self.BETAo * action[i] * (S[i] / Bu + ( e[i] * l_edge + ( 1-e[i] ) * l_cp ) / S[i])\n",
    "\n",
    "        self.Rl =   self.BETAl * ( ( 1 - action[i] )  * ( l_cp - ( e[i] * l_edge + ( 1 - e[i] ) * l_cp ) ) ) / S[i]\n",
    "\n",
    "        #self.Rh[i] = self.Rh[i] + self.Ro + self.Rl\n",
    "\n",
    "        return  self.Rh+self.Ro+self.Rl\n",
    "\n",
    "    def selectAction(self,env,uit):\n",
    "\n",
    "\n",
    "        self.lastAction = self.action\n",
    "        self.lastp = self.p\n",
    "        self.lastr = self.r\n",
    "\n",
    "        self.updateViewContent(uit[1])\n",
    "        self.r , self.p , self.e, self.S, self.l_edge, self.l_cp = env.getStatus()\n",
    "        \n",
    "        self.reward = self.getReward(self.lastr[self.u],self.lastp,self.r[self.u],self.p,self.W[-1],self.lastAction,self.S,self.Bu,self.l_edge,self.l_cp,self.e)\n",
    "        \n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.action[self.W[-1]] = 1\n",
    "\n",
    "        actionIndex = list(torch.randint(0,self.contentNum,(self.Bu,)))\n",
    "        \n",
    "        if self.W[-1] not in actionIndex:\n",
    "            actionIndex.pop()\n",
    "        for index in actionIndex:\n",
    "            self.action[index] = 1\n",
    "\n",
    "        env.updateEnv(self.u,self.action.numpy(),uit[2])\n",
    "\n",
    "        return self.action"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "num_episodes = 1\n",
    "TARGET_UPDATE = 1\n",
    "bestReward =  float(\"-inf\")\n",
    "\n",
    "env = ENV(userNum,contentNum)\n",
    "UEs = {}\n",
    "sumReward = np.zeros(3)\n",
    "loss = 0\n",
    "UEHit = np.zeros(userNum)\n",
    "edgeHit = 0\n",
    "\n",
    "rewardPara = {\"alpha\":1,\"betao\":0.5,\"betal\":0.5}\n",
    "\n",
    "sumHitrate = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "UEHitrate = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "edgeHitrate = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "privacyReduction = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    for index,trace in UIT.iterrows():\n",
    "        uit = trace.to_numpy()\n",
    "        if uit[0] not in UEs:\n",
    "            UEs[uit[0]] = UE_random(uit[0],env,rewardPara)\n",
    "\n",
    "        ue = UEs[uit[0]]\n",
    "        \n",
    "        actionIndex = np.argwhere(ue.lastAction)\n",
    "        if uit[1] in actionIndex:\n",
    "            UEHit[uit[0]] += 1\n",
    "        elif uit[1] in env.pipe.keys():\n",
    "            edgeHit += 1\n",
    "\n",
    "        ue.selectAction(env,uit)\n",
    "\n",
    "        sumReward[0] += float(ue.Rh)\n",
    "        sumReward[1] += float(ue.Rl)\n",
    "        sumReward[2] += float(ue.Ro)\n",
    "\n",
    "        if index % 10000 == 0 :\n",
    "            psi = 0\n",
    "            p = torch.from_numpy(env.p)\n",
    "            for u in UEs:\n",
    "                psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "            print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "            print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "            print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "            print()\n",
    "            sumHitrate[int(index // 10000)]   = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "            UEHitrate [int(index // 10000)]   = round(UEHit.sum()/(index+1),5)\n",
    "            edgeHitrate [int(index // 10000)] = round(edgeHit/(index+1),5)\n",
    "            privacyReduction [int(index // 10000)] = round(float(psi)/len(UEs),5)\n",
    "    psi = 0\n",
    "    p = torch.from_numpy(env.p)\n",
    "    for u in UEs:\n",
    "        psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "    print()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "    print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "    print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    sumHitrate [int(round(index / 10000,0))]  = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "    UEHitrate  [int(round(index / 10000,0))]  = round(UEHit.sum()/(index+1),5)\n",
    "    edgeHitrate[int(round(index / 10000,0))]  = round(edgeHit/(index+1),5)\n",
    "    privacyReduction [int(round(index / 10000,0))] = round(float(psi)/len(UEs),5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Time: Sun Sep 19 13:55:23 2021 Episode: 0   Index: 0   Loss: 0.0 --\n",
      "Reward: [0. 0. 0.] total reward: 0.0\n",
      "UEHitrate: 0.0  edgeHitrate 0.0 sumHitrate 0.0  privacy: 1.86387\n",
      "\n",
      "--Time: Sun Sep 19 13:55:36 2021 Episode: 0   Index: 10000   Loss: 0.0 --\n",
      "Reward: [-1.7722e+00  5.9890e-02  1.5600e-03] total reward: -1.71075\n",
      "UEHitrate: 0.0014  edgeHitrate 0.13359 sumHitrate 0.13499  privacy: 2.77671\n",
      "\n",
      "--Time: Sun Sep 19 13:55:48 2021 Episode: 0   Index: 20000   Loss: 0.0 --\n",
      "Reward: [-1.42213  0.06824  0.00209] total reward: -1.3518\n",
      "UEHitrate: 0.00165  edgeHitrate 0.15199 sumHitrate 0.15364  privacy: 2.80516\n",
      "\n",
      "--Time: Sun Sep 19 13:56:00 2021 Episode: 0   Index: 30000   Loss: 0.0 --\n",
      "Reward: [-1.17208  0.06414  0.00229] total reward: -1.10564\n",
      "UEHitrate: 0.0021  edgeHitrate 0.143 sumHitrate 0.1451  privacy: 2.75815\n",
      "\n",
      "--Time: Sun Sep 19 13:56:12 2021 Episode: 0   Index: 40000   Loss: 0.0 --\n",
      "Reward: [-1.04688  0.06291  0.00236] total reward: -0.98161\n",
      "UEHitrate: 0.00232  edgeHitrate 0.1401 sumHitrate 0.14242  privacy: 2.7121\n",
      "\n",
      "--Time: Sun Sep 19 13:56:24 2021 Episode: 0   Index: 50000   Loss: 0.0 --\n",
      "Reward: [-0.94663  0.06221  0.0025 ] total reward: -0.88192\n",
      "UEHitrate: 0.00268  edgeHitrate 0.1386 sumHitrate 0.14128  privacy: 2.64912\n",
      "\n",
      "--Time: Sun Sep 19 13:56:35 2021 Episode: 0   Index: 60000   Loss: 0.0 --\n",
      "Reward: [-0.86685  0.06138  0.00253] total reward: -0.80295\n",
      "UEHitrate: 0.0026  edgeHitrate 0.13666 sumHitrate 0.13926  privacy: 2.60369\n",
      "\n",
      "--Time: Sun Sep 19 13:56:47 2021 Episode: 0   Index: 70000   Loss: 0.0 --\n",
      "Reward: [-0.79508  0.0597   0.00241] total reward: -0.73297\n",
      "UEHitrate: 0.0026  edgeHitrate 0.13287 sumHitrate 0.13547  privacy: 2.56672\n",
      "\n",
      "--Time: Sun Sep 19 13:56:58 2021 Episode: 0   Index: 80000   Loss: 0.0 --\n",
      "Reward: [-0.75326  0.05942  0.00242] total reward: -0.69142\n",
      "UEHitrate: 0.00257  edgeHitrate 0.13227 sumHitrate 0.13485  privacy: 2.52858\n",
      "\n",
      "--Time: Sun Sep 19 13:57:10 2021 Episode: 0   Index: 90000   Loss: 0.0 --\n",
      "Reward: [-0.69687  0.05899  0.00246] total reward: -0.63542\n",
      "UEHitrate: 0.00267  edgeHitrate 0.13134 sumHitrate 0.13401  privacy: 2.48458\n",
      "\n",
      "--Time: Sun Sep 19 13:57:22 2021 Episode: 0   Index: 100000   Loss: 0.0 --\n",
      "Reward: [-0.63816  0.05853  0.00245] total reward: -0.57718\n",
      "UEHitrate: 0.00272  edgeHitrate 0.13028 sumHitrate 0.133  privacy: 2.43033\n",
      "\n",
      "--Time: Sun Sep 19 13:57:33 2021 Episode: 0   Index: 110000   Loss: 0.0 --\n",
      "Reward: [-0.58339  0.05861  0.00251] total reward: -0.52227\n",
      "UEHitrate: 0.00274  edgeHitrate 0.13053 sumHitrate 0.13326  privacy: 2.38963\n",
      "\n",
      "--Time: Sun Sep 19 13:57:45 2021 Episode: 0   Index: 120000   Loss: 0.0 --\n",
      "Reward: [-0.52903  0.05798  0.00253] total reward: -0.46852\n",
      "UEHitrate: 0.00285  edgeHitrate 0.12912 sumHitrate 0.13197  privacy: 2.36007\n",
      "\n",
      "--Time: Sun Sep 19 13:57:56 2021 Episode: 0   Index: 130000   Loss: 0.0 --\n",
      "Reward: [-0.49306  0.05744  0.00263] total reward: -0.43299\n",
      "UEHitrate: 0.00302  edgeHitrate 0.12795 sumHitrate 0.13097  privacy: 2.32344\n",
      "\n",
      "--Time: Sun Sep 19 13:58:08 2021 Episode: 0   Index: 140000   Loss: 0.0 --\n",
      "Reward: [-0.44045  0.05807  0.00268] total reward: -0.3797\n",
      "UEHitrate: 0.00309  edgeHitrate 0.12941 sumHitrate 0.1325  privacy: 2.29293\n",
      "\n",
      "--Time: Sun Sep 19 13:58:19 2021 Episode: 0   Index: 150000   Loss: 0.0 --\n",
      "Reward: [-0.41624  0.05863  0.00273] total reward: -0.35488\n",
      "UEHitrate: 0.00317  edgeHitrate 0.1306 sumHitrate 0.13377  privacy: 2.26416\n",
      "\n",
      "--Time: Sun Sep 19 13:58:30 2021 Episode: 0   Index: 160000   Loss: 0.0 --\n",
      "Reward: [-0.38425  0.05815  0.00284] total reward: -0.32326\n",
      "UEHitrate: 0.00318  edgeHitrate 0.12957 sumHitrate 0.13276  privacy: 2.23086\n",
      "\n",
      "--Time: Sun Sep 19 13:58:42 2021 Episode: 0   Index: 170000   Loss: 0.0 --\n",
      "Reward: [-0.3623   0.05853  0.00286] total reward: -0.30092\n",
      "UEHitrate: 0.00321  edgeHitrate 0.13041 sumHitrate 0.13361  privacy: 2.19814\n",
      "\n",
      "--Time: Sun Sep 19 13:58:53 2021 Episode: 0   Index: 180000   Loss: 0.0 --\n",
      "Reward: [-0.33179  0.05882  0.00291] total reward: -0.27007\n",
      "UEHitrate: 0.00321  edgeHitrate 0.13106 sumHitrate 0.13427  privacy: 2.16298\n",
      "\n",
      "--Time: Sun Sep 19 13:59:05 2021 Episode: 0   Index: 190000   Loss: 0.0 --\n",
      "Reward: [-0.3126   0.05853  0.00293] total reward: -0.25114\n",
      "UEHitrate: 0.00332  edgeHitrate 0.13043 sumHitrate 0.13374  privacy: 2.13354\n",
      "\n",
      "--Time: Sun Sep 19 13:59:16 2021 Episode: 0   Index: 200000   Loss: 0.0 --\n",
      "Reward: [-0.29686  0.05843  0.00294] total reward: -0.23548\n",
      "UEHitrate: 0.0033  edgeHitrate 0.13021 sumHitrate 0.13351  privacy: 2.10366\n",
      "\n",
      "--Time: Sun Sep 19 13:59:28 2021 Episode: 0   Index: 210000   Loss: 0.0 --\n",
      "Reward: [-0.27418  0.0589   0.00299] total reward: -0.21228\n",
      "UEHitrate: 0.00338  edgeHitrate 0.13124 sumHitrate 0.13461  privacy: 2.07048\n",
      "\n",
      "--Time: Sun Sep 19 13:59:39 2021 Episode: 0   Index: 220000   Loss: 0.0 --\n",
      "Reward: [-0.25645  0.05857  0.00302] total reward: -0.19487\n",
      "UEHitrate: 0.00342  edgeHitrate 0.13054 sumHitrate 0.13395  privacy: 2.03986\n",
      "\n",
      "--Time: Sun Sep 19 13:59:50 2021 Episode: 0   Index: 230000   Loss: 0.0 --\n",
      "Reward: [-0.24199  0.05838  0.00302] total reward: -0.18059\n",
      "UEHitrate: 0.00346  edgeHitrate 0.13011 sumHitrate 0.13357  privacy: 2.00891\n",
      "\n",
      "--Time: Sun Sep 19 14:00:02 2021 Episode: 0   Index: 240000   Loss: 0.0 --\n",
      "Reward: [-0.22202  0.05819  0.00305] total reward: -0.16078\n",
      "UEHitrate: 0.00348  edgeHitrate 0.12968 sumHitrate 0.13316  privacy: 1.98107\n",
      "\n",
      "--Time: Sun Sep 19 14:00:13 2021 Episode: 0   Index: 250000   Loss: 0.0 --\n",
      "Reward: [-0.20947  0.05834  0.00305] total reward: -0.14807\n",
      "UEHitrate: 0.00352  edgeHitrate 0.13005 sumHitrate 0.13357  privacy: 1.95427\n",
      "\n",
      "--Time: Sun Sep 19 14:00:24 2021 Episode: 0   Index: 260000   Loss: 0.0 --\n",
      "Reward: [-0.20139  0.05827  0.00306] total reward: -0.14006\n",
      "UEHitrate: 0.00357  edgeHitrate 0.12988 sumHitrate 0.13345  privacy: 1.92775\n",
      "\n",
      "--Time: Sun Sep 19 14:00:36 2021 Episode: 0   Index: 270000   Loss: 0.0 --\n",
      "Reward: [-0.18985  0.05783  0.00308] total reward: -0.12893\n",
      "UEHitrate: 0.00363  edgeHitrate 0.12891 sumHitrate 0.13254  privacy: 1.90121\n",
      "\n",
      "--Time: Sun Sep 19 14:00:47 2021 Episode: 0   Index: 280000   Loss: 0.0 --\n",
      "Reward: [-0.18677  0.05797  0.0031 ] total reward: -0.1257\n",
      "UEHitrate: 0.00365  edgeHitrate 0.12923 sumHitrate 0.13289  privacy: 1.87534\n",
      "\n",
      "--Time: Sun Sep 19 14:00:59 2021 Episode: 0   Index: 290000   Loss: 0.0 --\n",
      "Reward: [-0.18051  0.05843  0.00311] total reward: -0.11896\n",
      "UEHitrate: 0.00366  edgeHitrate 0.13027 sumHitrate 0.13393  privacy: 1.85052\n",
      "\n",
      "--Time: Sun Sep 19 14:01:10 2021 Episode: 0   Index: 300000   Loss: 0.0 --\n",
      "Reward: [-0.17251  0.05883  0.0031 ] total reward: -0.11058\n",
      "UEHitrate: 0.00368  edgeHitrate 0.13113 sumHitrate 0.1348  privacy: 1.82693\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "--Time: Sun Sep 19 14:01:11 2021 Episode: 0   Index: 300982   Loss: 0.0 --\n",
      "Reward: [-0.17184  0.05885  0.0031 ] total reward: -0.10989\n",
      "UEHitrate: 0.00368  edgeHitrate 0.13117 sumHitrate 0.13485  privacy: 1.82469\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sumHitrate, UEHitrate, edgeHitrate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.     , 0.13499, 0.15364, 0.1451 , 0.14242, 0.14128, 0.13926,\n",
       "        0.13547, 0.13485, 0.13401, 0.133  , 0.13326, 0.13197, 0.13097,\n",
       "        0.1325 , 0.13377, 0.13276, 0.13361, 0.13427, 0.13374, 0.13351,\n",
       "        0.13461, 0.13395, 0.13357, 0.13316, 0.13357, 0.13345, 0.13254,\n",
       "        0.13289, 0.13393, 0.13485, 0.     ]),\n",
       " array([0.     , 0.0014 , 0.00165, 0.0021 , 0.00232, 0.00268, 0.0026 ,\n",
       "        0.0026 , 0.00257, 0.00267, 0.00272, 0.00274, 0.00285, 0.00302,\n",
       "        0.00309, 0.00317, 0.00318, 0.00321, 0.00321, 0.00332, 0.0033 ,\n",
       "        0.00338, 0.00342, 0.00346, 0.00348, 0.00352, 0.00357, 0.00363,\n",
       "        0.00365, 0.00366, 0.00368, 0.     ]),\n",
       " array([0.     , 0.13359, 0.15199, 0.143  , 0.1401 , 0.1386 , 0.13666,\n",
       "        0.13287, 0.13227, 0.13134, 0.13028, 0.13053, 0.12912, 0.12795,\n",
       "        0.12941, 0.1306 , 0.12957, 0.13041, 0.13106, 0.13043, 0.13021,\n",
       "        0.13124, 0.13054, 0.13011, 0.12968, 0.13005, 0.12988, 0.12891,\n",
       "        0.12923, 0.13027, 0.13117, 0.     ]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "privacyReduction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.86387, 2.77671, 2.80516, 2.75815, 2.7121 , 2.64912, 2.60369,\n",
       "       2.56672, 2.52858, 2.48458, 2.43033, 2.38963, 2.36007, 2.32344,\n",
       "       2.29293, 2.26416, 2.23086, 2.19814, 2.16298, 2.13354, 2.10366,\n",
       "       2.07048, 2.03986, 2.00891, 1.98107, 1.95427, 1.92775, 1.90121,\n",
       "       1.87534, 1.85052, 1.82469, 0.     ])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class UE_None(object):\n",
    "    def __init__(self,u,env,rewardPara):\n",
    "        self.u = u\n",
    "\n",
    "        self.W = []\n",
    "        self.v = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "\n",
    "        self.Bu = int(env.B[self.u])\n",
    "        self.contentNum = env.contentNum\n",
    "        self.userNum = env.userNum\n",
    "\n",
    "        self.r , self.p , self.e, self.S,self.l_edge, self.l_cp = env.getStatus()\n",
    "\n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.lastAction = self.action\n",
    "\n",
    "        self.reward = 0\n",
    "        self.ALPHAh = rewardPara['alpha']\n",
    "        self.BETAo =  rewardPara['betao']\n",
    "        self.BETAl =  rewardPara['betal']\n",
    "\n",
    "    def updateViewContent(self,i):\n",
    "        self.W.append(i)\n",
    "        self.v[i] = 1\n",
    "\n",
    "    \n",
    "    def getReward(self,lastru,lastp,ru,p,i,action,S,Bu,l_edge,l_cp,e):\n",
    "\n",
    "        self.Rh = - self.ALPHAh * (torch.log(lastru * lastp + (1-lastru) * (1-lastp)).sum() - torch.log(ru * p + (1-ru) * (1-p)).sum())\n",
    "\n",
    "        self.Ro =   self.BETAo * action[i] * (S[i] / Bu + ( e[i] * l_edge + ( 1-e[i] ) * l_cp ) / S[i])\n",
    "\n",
    "        self.Rl =   self.BETAl * ( ( 1 - action[i] )  * ( l_cp - ( e[i] * l_edge + ( 1 - e[i] ) * l_cp ) ) ) / S[i]\n",
    "\n",
    "        #self.Rh[i] = self.Rh[i] + self.Ro + self.Rl\n",
    "\n",
    "        return  self.Rh+self.Ro+self.Rl\n",
    "\n",
    "    def selectAction(self,env,uit):\n",
    "\n",
    "        self.lastAction = self.action\n",
    "        self.lastp = self.p\n",
    "        self.lastr = self.r\n",
    "\n",
    "        self.updateViewContent(uit[1])\n",
    "        self.r , self.p , self.e, self.S, self.l_edge, self.l_cp = env.getStatus()\n",
    "        \n",
    "        self.reward = self.getReward(self.lastr[self.u],self.lastp,self.r[self.u],self.p,self.W[-1],self.lastAction,self.S,self.Bu,self.l_edge,self.l_cp,self.e)\n",
    "        \n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.action[self.W[-1]] = 1\n",
    "\n",
    "        env.updateEnv(self.u,self.action.numpy(),uit[2])\n",
    "\n",
    "        return self.action"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "num_episodes = 1\n",
    "TARGET_UPDATE = 1\n",
    "bestReward =  float(\"-inf\")\n",
    "\n",
    "env = ENV(userNum,contentNum)\n",
    "UEs = {}\n",
    "sumReward = np.zeros(3)\n",
    "loss = 0\n",
    "UEHit = np.zeros(userNum)\n",
    "edgeHit = 0\n",
    "\n",
    "rewardPara = {\"alpha\":1,\"betao\":0.5,\"betal\":0.5}\n",
    "\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    for index,trace in trainUIT.iterrows():\n",
    "        uit = trace.to_numpy()\n",
    "        if uit[0] not in UEs:\n",
    "            UEs[uit[0]] = UE_None(uit[0],env,rewardPara)\n",
    "\n",
    "        ue = UEs[uit[0]]\n",
    "        \n",
    "        actionIndex = np.argwhere(ue.lastAction)\n",
    "        if uit[1] in actionIndex:\n",
    "            UEHit[uit[0]] += 1\n",
    "        elif uit[1] in env.pipe.keys():\n",
    "            edgeHit += 1\n",
    "\n",
    "        ue.selectAction(env,uit)\n",
    "\n",
    "        sumReward[0] += float(ue.Rh)\n",
    "        sumReward[1] += float(ue.Rl)\n",
    "        sumReward[2] += float(ue.Ro)\n",
    "\n",
    "        if index % 10000 == 0 :\n",
    "            psi = 0\n",
    "            p = torch.from_numpy(env.p)\n",
    "            for u in UEs:\n",
    "                psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "            print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "            print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "            print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "            print()\n",
    "            sumHitrate[int(index // 10000)]   = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "            UEHitrate [int(index // 10000)]   = round(UEHit.sum()/(index+1),5)\n",
    "            edgeHitrate [int(index // 10000)] = round(edgeHit/(index+1),5)\n",
    "\n",
    "    psi = 0\n",
    "    p = torch.from_numpy(env.p)\n",
    "    for u in UEs:\n",
    "        psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "    print()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "    print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "    print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Time: Wed Sep 15 22:04:35 2021 Episode: 0   Index: 0   Loss: 0.0 --\n",
      "Reward: [0. 0. 0.] total reward: 0.0\n",
      "UEHitrate: 0.0  edgeHitrate 0.0 sumHitrate 0.0  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:04:45 2021 Episode: 0   Index: 10000   Loss: 0.0 --\n",
      "Reward: [0.10938 0.1794  0.00074] total reward: 0.28952\n",
      "UEHitrate: 0.0018  edgeHitrate 0.39936 sumHitrate 0.40116  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:04:55 2021 Episode: 0   Index: 20000   Loss: 0.0 --\n",
      "Reward: [0.03867 0.18685 0.00087] total reward: 0.22639\n",
      "UEHitrate: 0.00195  edgeHitrate 0.41593 sumHitrate 0.41788  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:05:05 2021 Episode: 0   Index: 30000   Loss: 0.0 --\n",
      "Reward: [0.01672 0.19601 0.00083] total reward: 0.21356\n",
      "UEHitrate: 0.0024  edgeHitrate 0.43615 sumHitrate 0.43855  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:05:15 2021 Episode: 0   Index: 40000   Loss: 0.0 --\n",
      "Reward: [0.01123 0.19757 0.00101] total reward: 0.20981\n",
      "UEHitrate: 0.00247  edgeHitrate 0.43974 sumHitrate 0.44221  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:05:25 2021 Episode: 0   Index: 50000   Loss: 0.0 --\n",
      "Reward: [0.0048  0.19843 0.00096] total reward: 0.20419\n",
      "UEHitrate: 0.00246  edgeHitrate 0.44157 sumHitrate 0.44403  privacy: 1.0\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "--Time: Wed Sep 15 22:05:32 2021 Episode: 0   Index: 56743   Loss: 0.0 --\n",
      "Reward: [-0.00056  0.19738  0.00101] total reward: 0.19783\n",
      "UEHitrate: 0.00252  edgeHitrate 0.43924 sumHitrate 0.44176  privacy: 1.0\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "num_episodes = 1\n",
    "TARGET_UPDATE = 1\n",
    "bestReward =  float(\"-inf\")\n",
    "\n",
    "env = ENV(userNum,contentNum)\n",
    "UEs = {}\n",
    "sumReward = np.zeros(3)\n",
    "loss = 0\n",
    "UEHit = np.zeros(userNum)\n",
    "edgeHit = 0\n",
    "\n",
    "rewardPara = {\"alpha\":1,\"betao\":0.5,\"betal\":0.5}\n",
    "\n",
    "sumHitrate = np.zeros(10)\n",
    "UEHitrate = np.zeros(10)\n",
    "edgeHitrate = np.zeros(10)\n",
    "privacyReduction = np.zeros(10)\n",
    "\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    for index,trace in UIT.iterrows():\n",
    "        uit = trace.to_numpy()\n",
    "        if uit[0] not in UEs:\n",
    "            UEs[uit[0]] = UE_None(uit[0],env,rewardPara)\n",
    "\n",
    "        ue = UEs[uit[0]]\n",
    "        \n",
    "        actionIndex = np.argwhere(ue.lastAction)\n",
    "        if uit[1] in actionIndex:\n",
    "            UEHit[uit[0]] += 1\n",
    "        elif uit[1] in env.pipe.keys():\n",
    "            edgeHit += 1\n",
    "\n",
    "        ue.selectAction(env,uit)\n",
    "\n",
    "        sumReward[0] += float(ue.Rh)\n",
    "        sumReward[1] += float(ue.Rl)\n",
    "        sumReward[2] += float(ue.Ro)\n",
    "\n",
    "        if index % 10000 == 0 :\n",
    "            psi = 0\n",
    "            p = torch.from_numpy(env.p)\n",
    "            for u in UEs:\n",
    "                psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "            print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "            print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "            print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "            print()\n",
    "            sumHitrate[int(index // 10000)]   = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "            UEHitrate [int(index // 10000)]   = round(UEHit.sum()/(index+1),5)\n",
    "            edgeHitrate [int(index // 10000)] = round(edgeHit/(index+1),5)\n",
    "            privacyReduction [int(index // 10000)] = round(float(psi)/len(UEs),5)\n",
    "    psi = 0\n",
    "    p = torch.from_numpy(env.p)\n",
    "    for u in UEs:\n",
    "        psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "    print()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "    print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "    print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    sumHitrate [int(round(index / 10000,0))]  = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "    UEHitrate  [int(round(index / 10000,0))]  = round(UEHit.sum()/(index+1),5)\n",
    "    edgeHitrate[int(round(index / 10000,0))]  = round(edgeHit/(index+1),5)\n",
    "    privacyReduction [int(round(index / 10000,0))] = round(float(psi)/len(UEs),5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Time: Wed Sep 15 22:59:36 2021 Episode: 0   Index: 0   Loss: 0.0 --\n",
      "Reward: [0. 0. 0.] total reward: 0.0\n",
      "UEHitrate: 0.0  edgeHitrate 0.0 sumHitrate 0.0  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:59:47 2021 Episode: 0   Index: 10000   Loss: 0.0 --\n",
      "Reward: [0.10938 0.1794  0.00074] total reward: 0.28952\n",
      "UEHitrate: 0.0018  edgeHitrate 0.39936 sumHitrate 0.40116  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:59:58 2021 Episode: 0   Index: 20000   Loss: 0.0 --\n",
      "Reward: [0.03867 0.18685 0.00087] total reward: 0.22639\n",
      "UEHitrate: 0.00195  edgeHitrate 0.41593 sumHitrate 0.41788  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:09 2021 Episode: 0   Index: 30000   Loss: 0.0 --\n",
      "Reward: [0.01672 0.19601 0.00083] total reward: 0.21356\n",
      "UEHitrate: 0.0024  edgeHitrate 0.43615 sumHitrate 0.43855  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:20 2021 Episode: 0   Index: 40000   Loss: 0.0 --\n",
      "Reward: [0.01123 0.19757 0.00101] total reward: 0.20981\n",
      "UEHitrate: 0.00247  edgeHitrate 0.43974 sumHitrate 0.44221  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:31 2021 Episode: 0   Index: 50000   Loss: 0.0 --\n",
      "Reward: [0.0048  0.19843 0.00096] total reward: 0.20419\n",
      "UEHitrate: 0.00246  edgeHitrate 0.44157 sumHitrate 0.44403  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:42 2021 Episode: 0   Index: 60000   Loss: 0.0 --\n",
      "Reward: [-0.00059  0.197    0.00102] total reward: 0.19742\n",
      "UEHitrate: 0.00258  edgeHitrate 0.43834 sumHitrate 0.44093  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:53 2021 Episode: 0   Index: 70000   Loss: 0.0 --\n",
      "Reward: [-0.00434  0.19787  0.00103] total reward: 0.19456\n",
      "UEHitrate: 0.0028  edgeHitrate 0.44025 sumHitrate 0.44305  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:01:03 2021 Episode: 0   Index: 80000   Loss: 0.0 --\n",
      "Reward: [-0.0076   0.19829  0.001  ] total reward: 0.1917\n",
      "UEHitrate: 0.00297  edgeHitrate 0.44133 sumHitrate 0.44431  privacy: 1.0\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "--Time: Wed Sep 15 23:01:14 2021 Episode: 0   Index: 89292   Loss: 0.0 --\n",
      "Reward: [-0.00976  0.20089  0.00102] total reward: 0.19215\n",
      "UEHitrate: 0.00298  edgeHitrate 0.44711 sumHitrate 0.45009  privacy: 1.0\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "sumHitrate, UEHitrate, edgeHitrate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.     , 0.40116, 0.41788, 0.43855, 0.44221, 0.44403, 0.44093,\n",
       "        0.44305, 0.44431, 0.45009]),\n",
       " array([0.     , 0.0018 , 0.00195, 0.0024 , 0.00247, 0.00246, 0.00258,\n",
       "        0.0028 , 0.00297, 0.00298]),\n",
       " array([0.     , 0.39936, 0.41593, 0.43615, 0.43974, 0.44157, 0.43834,\n",
       "        0.44025, 0.44133, 0.44711]))"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "privacyReduction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53e075add4fc865efaed3001cae69f5b66291fd877e6c0fafb5013552ba051ca"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}