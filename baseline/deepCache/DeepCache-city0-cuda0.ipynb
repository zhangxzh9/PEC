{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#from torchtext.datasets import Multi30k\n",
    "#from torchtext.data import Field, BucketIterator\n",
    "\n",
    "#import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self,data = None,src_len = 20,trg_len=26):\n",
    "        self.data = data\n",
    "        self.data_lengths = len(data)\n",
    "        self.src_len = src_len\n",
    "        self.trg_len = trg_len\n",
    "    def __getitem__(self,index):\n",
    "        data=self.data[index]\n",
    "        src_data = data[0:self.src_len]\n",
    "        trg_data = data[self.src_len:self.trg_len+self.src_len]\n",
    "        return src_data,trg_data\n",
    "    def __len__(self):\n",
    "        return self.data_lengths\n",
    "\n",
    "def dataset_iter(trDataX ,trDataY):\n",
    "    trData = pd.concat([trDataX, trDataY], axis=1).to_numpy()\n",
    "    trData = trData[:,:,np.newaxis]\n",
    "    train_data, validate_data = np.split(trData, [int(.5*len(trData))])\n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset=Dataset(train_data,src_len = 20,trg_len=26),batch_size=BATCHSIZE)\n",
    "    validate_data_loader = torch.utils.data.DataLoader(dataset=Dataset(validate_data,src_len = 20,trg_len=26),batch_size=BATCHSIZE)\n",
    "    return train_data_loader,validate_data_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        #self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        embedded = self.dropout(src)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        #self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.rnn = nn.LSTM(output_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input_ = input_.float().unsqueeze(0)\n",
    "        #print(\"decode input shape\",input_.shape)\n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(input))\n",
    "        embedded = self.dropout(input_)\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        #prediction = self.fc_out(output.squeeze(0)).unsqueeze(-1)\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #print(prediction.shape)\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        #print(\"trg_len\",trg.shape[0],\"batch_size\",trg.shape[1])\n",
    "        trg_feature_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_feature_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        \n",
    "        hidden, cell = self.encoder(src[0:-1])\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input_ = src[-1]\n",
    "        output, hidden, cell = self.decoder(input_, hidden, cell)\n",
    "        \n",
    "        #print(input.shape)\n",
    "        for t in range(0, trg_len):\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            #top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            #print(trg[t].shape,output.unsqueeze(-1).shape)\n",
    "            input_ = trg[t] if teacher_force else output\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input_, hidden, cell)\n",
    "            \n",
    "            #print(\"output.shape\",output.shape)[20000, 1]\n",
    "            \n",
    "        return outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch[0].permute(1,0,2).float().to(device)\n",
    "        trg = batch[1].permute(1,0,2).float().to(device)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #print(src.shape,trg.shape)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        #print(output.shape,trg.shape)\n",
    "        #output_dim = output.shape[-1]\n",
    "        #if i%50 == 0:\n",
    "        #    print(\"output[0],trg[0]\",f'{output[0].sum():.8f}',f'{trg[0].sum():.8f}')    \n",
    "        #    print(\"output[10],trg[10]\",f'{output[10].sum():.8f}',f'{trg[10].sum():.8f}')  \n",
    "        #    print(\"output[25],trg[25]\",f'{output[25].sum():.8f}',f'{trg[25].sum():.8f}')  \n",
    "        \n",
    "        batchsize = trg.shape[1]\n",
    "        \n",
    "        #output = output[1:].view(-1)\n",
    "        output = output.permute(1,0,2).reshape(batchsize,-1)\n",
    "        \n",
    "        #trg = trg[1:].view(-1)\n",
    "        trg = trg.permute(1,0,2).reshape(batchsize,-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(\"train total epoch_loss\",epoch_loss,\"avarage epoch_loss\",epoch_loss / len(iterator))    \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch[0].permute(1,0,2).float().cuda()\n",
    "            trg = batch[1].permute(1,0,2).float().cuda()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            #$print(output[1],trg[1])\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "            #if i%50 == 0:\n",
    "                #print(\"output[0].sum(),trg[0].sum()\",output[0].sum(),trg[0].sum())\n",
    " \n",
    "            batchsize = trg.shape[1]\n",
    "            \n",
    "            #output = output[1:].view(-1)\n",
    "            output = output.permute(1,0,2).reshape(batchsize,-1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #trg = trg[1:].view(-1)\n",
    "            trg = trg.permute(1,0,2).reshape(batchsize,-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "    print(\"vali total epoch_loss\",epoch_loss,\"avarage epoch_loss\",epoch_loss / len(iterator)) \n",
    "    return epoch_loss / len(iterator)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "FOLD = 2\n",
    "CITY = 0\n",
    "BATCHSIZE = 80000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "trDataX  = pd.read_csv(\"fold{}_city{}_trainX.csv\".format(FOLD,CITY),header=None)\n",
    "trDataY  = pd.read_csv(\"fold{}_city{}_trainY.csv\".format(FOLD,CITY),header=None)\n",
    "train_iterator,valid_iterator = dataset_iter(trDataX,trDataY)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    if i ==0:\n",
    "        print(len(batch),batch[0].permute(1,0,2)[0:-1].shape,batch[0].permute(1,0,2)[-1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 torch.Size([19, 80000, 1]) torch.Size([80000, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#model init\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 64\n",
    "#HID_DIM = 64\n",
    "\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 100,929 trainable parameters\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'fold{}-city{}-model.pt'.format(FOLD,CITY))\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5e} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5e} ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train total epoch_loss 0.0007147481146603241 avarage epoch_loss 2.102200337236247e-05\n",
      "vali total epoch_loss 4.482545239170577e-05 avarage epoch_loss 1.3183956585795813e-06\n",
      "Epoch: 01 | Time: 1m 14s\n",
      "\tTrain Loss: 2.10220e-05 \n",
      "\t Val. Loss: 1.31840e-06 \n",
      "train total epoch_loss 0.00011733774067579361 avarage epoch_loss 3.4511100198762826e-06\n",
      "vali total epoch_loss 4.427749411206605e-05 avarage epoch_loss 1.302279238590178e-06\n",
      "Epoch: 02 | Time: 1m 17s\n",
      "\tTrain Loss: 3.45111e-06 \n",
      "\t Val. Loss: 1.30228e-06 \n",
      "train total epoch_loss 6.683219942260621e-05 avarage epoch_loss 1.9656529241943005e-06\n",
      "vali total epoch_loss 4.39892037888967e-05 avarage epoch_loss 1.2938001114381383e-06\n",
      "Epoch: 03 | Time: 1m 15s\n",
      "\tTrain Loss: 1.96565e-06 \n",
      "\t Val. Loss: 1.29380e-06 \n",
      "train total epoch_loss 4.9515546038492175e-05 avarage epoch_loss 1.456339589367417e-06\n",
      "vali total epoch_loss 4.39058741790177e-05 avarage epoch_loss 1.291349240559344e-06\n",
      "Epoch: 04 | Time: 1m 20s\n",
      "\tTrain Loss: 1.45634e-06 \n",
      "\t Val. Loss: 1.29135e-06 \n",
      "train total epoch_loss 4.174075553464718e-05 avarage epoch_loss 1.2276692804307993e-06\n",
      "vali total epoch_loss 4.3864948565897066e-05 avarage epoch_loss 1.2901455460557962e-06\n",
      "Epoch: 05 | Time: 1m 14s\n",
      "\tTrain Loss: 1.22767e-06 \n",
      "\t Val. Loss: 1.29015e-06 \n",
      "train total epoch_loss 3.7896435401307826e-05 avarage epoch_loss 1.114601041214936e-06\n",
      "vali total epoch_loss 4.383066732316365e-05 avarage epoch_loss 1.2891372742106956e-06\n",
      "Epoch: 06 | Time: 1m 13s\n",
      "\tTrain Loss: 1.11460e-06 \n",
      "\t Val. Loss: 1.28914e-06 \n",
      "train total epoch_loss 3.584435955872323e-05 avarage epoch_loss 1.0542458693742126e-06\n",
      "vali total epoch_loss 4.381265739539231e-05 avarage epoch_loss 1.288607570452715e-06\n",
      "Epoch: 07 | Time: 1m 15s\n",
      "\tTrain Loss: 1.05425e-06 \n",
      "\t Val. Loss: 1.28861e-06 \n",
      "train total epoch_loss 3.4670545801418484e-05 avarage epoch_loss 1.0197219353358378e-06\n",
      "vali total epoch_loss 4.38038307493116e-05 avarage epoch_loss 1.288347963215047e-06\n",
      "Epoch: 08 | Time: 1m 18s\n",
      "\tTrain Loss: 1.01972e-06 \n",
      "\t Val. Loss: 1.28835e-06 \n",
      "train total epoch_loss 3.394423544023084e-05 avarage epoch_loss 9.983598658891424e-07\n",
      "vali total epoch_loss 4.3796084298719506e-05 avarage epoch_loss 1.2881201264329267e-06\n",
      "Epoch: 09 | Time: 1m 15s\n",
      "\tTrain Loss: 9.98360e-07 \n",
      "\t Val. Loss: 1.28812e-06 \n",
      "train total epoch_loss 3.346938098047758e-05 avarage epoch_loss 9.843935582493406e-07\n",
      "vali total epoch_loss 4.379503224072323e-05 avarage epoch_loss 1.2880891835506833e-06\n",
      "Epoch: 10 | Time: 1m 20s\n",
      "\tTrain Loss: 9.84394e-07 \n",
      "\t Val. Loss: 1.28809e-06 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "FOLD = 1\n",
    "CITY = 0\n",
    "BATCHSIZE = 40000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "trDataX  = pd.read_csv(\"fold{}_city{}_trainX.csv\".format(FOLD,CITY),header=None)\n",
    "trDataY  = pd.read_csv(\"fold{}_city{}_trainY.csv\".format(FOLD,CITY),header=None)\n",
    "train_iterator,valid_iterator = dataset_iter(trDataX,trDataY)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fold1_city0_trainX.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a25eddae52a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrDataX\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fold{}_city{}_trainX.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrDataY\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fold{}_city{}_trainY.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrDataX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrDataY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fold1_city0_trainX.csv'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    if i ==0:\n",
    "        print(len(batch),batch[0].permute(1,0,2)[0:-1].shape,batch[0].permute(1,0,2)[-1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 torch.Size([19, 40000, 1]) torch.Size([40000, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model init\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 64\n",
    "#HID_DIM = 64\n",
    "\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 100,929 trainable parameters\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'fold{}-city{}-model.pt'.format(FOLD,CITY))\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5e} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5e} ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train total epoch_loss 0.0007102853362539463 avarage epoch_loss 7.322529239731405e-06\n",
      "vali total epoch_loss 8.758953022436344e-06 avarage epoch_loss 9.0298484767385e-08\n",
      "Epoch: 01 | Time: 4m 41s\n",
      "\tTrain Loss: 7.32253e-06 \n",
      "\t Val. Loss: 9.02985e-08 \n",
      "train total epoch_loss 4.053834062744954e-05 avarage epoch_loss 4.1792103739638704e-07\n",
      "vali total epoch_loss 8.405491659146946e-06 avarage epoch_loss 8.665455318708193e-08\n",
      "Epoch: 02 | Time: 4m 42s\n",
      "\tTrain Loss: 4.17921e-07 \n",
      "\t Val. Loss: 8.66546e-08 \n",
      "train total epoch_loss 2.3767039252220457e-05 avarage epoch_loss 2.450210232187676e-07\n",
      "vali total epoch_loss 8.401569985494461e-06 avarage epoch_loss 8.661412356179857e-08\n",
      "Epoch: 03 | Time: 4m 39s\n",
      "\tTrain Loss: 2.45021e-07 \n",
      "\t Val. Loss: 8.66141e-08 \n",
      "train total epoch_loss 1.9530461223382645e-05 avarage epoch_loss 2.0134496106580046e-07\n",
      "vali total epoch_loss 8.398560389366594e-06 avarage epoch_loss 8.658309679759376e-08\n",
      "Epoch: 04 | Time: 4m 40s\n",
      "\tTrain Loss: 2.01345e-07 \n",
      "\t Val. Loss: 8.65831e-08 \n",
      "train total epoch_loss 1.784356674505716e-05 avarage epoch_loss 1.8395429634079547e-07\n",
      "vali total epoch_loss 8.394872427430755e-06 avarage epoch_loss 8.654507657145108e-08\n",
      "Epoch: 05 | Time: 4m 40s\n",
      "\tTrain Loss: 1.83954e-07 \n",
      "\t Val. Loss: 8.65451e-08 \n",
      "train total epoch_loss 1.700660844505819e-05 avarage epoch_loss 1.7532586025833188e-07\n",
      "vali total epoch_loss 8.393012102203556e-06 avarage epoch_loss 8.65258979608614e-08\n",
      "Epoch: 06 | Time: 4m 43s\n",
      "\tTrain Loss: 1.75326e-07 \n",
      "\t Val. Loss: 8.65259e-08 \n",
      "train total epoch_loss 1.6538262123333425e-05 avarage epoch_loss 1.7049754766323119e-07\n",
      "vali total epoch_loss 8.391507510197016e-06 avarage epoch_loss 8.651038670306203e-08\n",
      "Epoch: 07 | Time: 4m 41s\n",
      "\tTrain Loss: 1.70498e-07 \n",
      "\t Val. Loss: 8.65104e-08 \n",
      "train total epoch_loss 1.624804826150239e-05 avarage epoch_loss 1.6750565218043702e-07\n",
      "vali total epoch_loss 8.390696191185043e-06 avarage epoch_loss 8.650202258953652e-08\n",
      "Epoch: 08 | Time: 4m 43s\n",
      "\tTrain Loss: 1.67506e-07 \n",
      "\t Val. Loss: 8.65020e-08 \n",
      "train total epoch_loss 1.6057891137677416e-05 avarage epoch_loss 1.6554526946059191e-07\n",
      "vali total epoch_loss 8.390036295935488e-06 avarage epoch_loss 8.649521954572667e-08\n",
      "Epoch: 09 | Time: 4m 41s\n",
      "\tTrain Loss: 1.65545e-07 \n",
      "\t Val. Loss: 8.64952e-08 \n",
      "train total epoch_loss 1.5926194052440223e-05 avarage epoch_loss 1.6418756755093014e-07\n",
      "vali total epoch_loss 8.39014862208387e-06 avarage epoch_loss 8.64963775472564e-08\n",
      "Epoch: 10 | Time: 4m 47s\n",
      "\tTrain Loss: 1.64188e-07 \n",
      "\t Val. Loss: 8.64964e-08 \n",
      "train total epoch_loss 1.5832870197129978e-05 avarage epoch_loss 1.6322546594979358e-07\n",
      "vali total epoch_loss 8.389571675593288e-06 avarage epoch_loss 8.649042964529163e-08\n",
      "Epoch: 11 | Time: 4m 45s\n",
      "\tTrain Loss: 1.63225e-07 \n",
      "\t Val. Loss: 8.64904e-08 \n",
      "train total epoch_loss 1.575993447744395e-05 avarage epoch_loss 1.6247355131385513e-07\n",
      "vali total epoch_loss 8.389406456643655e-06 avarage epoch_loss 8.648872635715108e-08\n",
      "Epoch: 12 | Time: 4m 43s\n",
      "\tTrain Loss: 1.62474e-07 \n",
      "\t Val. Loss: 8.64887e-08 \n",
      "train total epoch_loss 1.5705976707636182e-05 avarage epoch_loss 1.6191728564573383e-07\n",
      "vali total epoch_loss 8.389230618632837e-06 avarage epoch_loss 8.648691359415296e-08\n",
      "Epoch: 13 | Time: 4m 40s\n",
      "\tTrain Loss: 1.61917e-07 \n",
      "\t Val. Loss: 8.64869e-08 \n",
      "train total epoch_loss 1.5662750570299977e-05 avarage epoch_loss 1.614716553639173e-07\n",
      "vali total epoch_loss 8.389074562131782e-06 avarage epoch_loss 8.648530476424518e-08\n",
      "Epoch: 14 | Time: 4m 42s\n",
      "\tTrain Loss: 1.61472e-07 \n",
      "\t Val. Loss: 8.64853e-08 \n",
      "train total epoch_loss 1.562677873323537e-05 avarage epoch_loss 1.6110081168283885e-07\n",
      "vali total epoch_loss 8.38906665023842e-06 avarage epoch_loss 8.648522319833422e-08\n",
      "Epoch: 15 | Time: 4m 40s\n",
      "\tTrain Loss: 1.61101e-07 \n",
      "\t Val. Loss: 8.64852e-08 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FOLD = 2\n",
    "CITY = 0\n",
    "BATCHSIZE = 40000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "trDataX  = pd.read_csv(\"fold{}_city{}_trainX.csv\".format(FOLD,CITY),header=None)\n",
    "trDataY  = pd.read_csv(\"fold{}_city{}_trainY.csv\".format(FOLD,CITY),header=None)\n",
    "train_iterator,valid_iterator = dataset_iter(trDataX,trDataY)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    if i ==0:\n",
    "        print(len(batch),batch[0].permute(1,0,2)[0:-1].shape,batch[0].permute(1,0,2)[-1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 torch.Size([19, 40000, 1]) torch.Size([40000, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model init\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 64\n",
    "#HID_DIM = 64\n",
    "\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 100,929 trainable parameters\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'fold{}-city{}-model.pt'.format(FOLD,CITY))\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5e} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5e} ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train total epoch_loss 0.014087991313317616 avarage epoch_loss 0.0001059247467166738\n",
      "vali total epoch_loss 2.1595675690377902e-05 avarage epoch_loss 1.623735014314128e-07\n",
      "Epoch: 01 | Time: 6m 25s\n",
      "\tTrain Loss: 1.05925e-04 \n",
      "\t Val. Loss: 1.62374e-07 \n",
      "train total epoch_loss 0.0003850793725632684 avarage epoch_loss 2.895333628295251e-06\n",
      "vali total epoch_loss 1.635246965747683e-05 avarage epoch_loss 1.2295089968027694e-07\n",
      "Epoch: 02 | Time: 6m 26s\n",
      "\tTrain Loss: 2.89533e-06 \n",
      "\t Val. Loss: 1.22951e-07 \n",
      "train total epoch_loss 0.0001843729476718181 avarage epoch_loss 1.3862627644497603e-06\n",
      "vali total epoch_loss 1.3366218908572591e-05 avarage epoch_loss 1.0049788653062099e-07\n",
      "Epoch: 03 | Time: 6m 26s\n",
      "\tTrain Loss: 1.38626e-06 \n",
      "\t Val. Loss: 1.00498e-07 \n",
      "train total epoch_loss 9.869825726127601e-05 avarage epoch_loss 7.420921598592181e-07\n",
      "vali total epoch_loss 1.1791226803836707e-05 avarage epoch_loss 8.865584063035118e-08\n",
      "Epoch: 04 | Time: 6m 25s\n",
      "\tTrain Loss: 7.42092e-07 \n",
      "\t Val. Loss: 8.86558e-08 \n",
      "train total epoch_loss 6.106459778720819e-05 avarage epoch_loss 4.5913231418953525e-07\n",
      "vali total epoch_loss 1.1087748788440877e-05 avarage epoch_loss 8.336653224391636e-08\n",
      "Epoch: 05 | Time: 6m 27s\n",
      "\tTrain Loss: 4.59132e-07 \n",
      "\t Val. Loss: 8.33665e-08 \n",
      "train total epoch_loss 4.364693961633748e-05 avarage epoch_loss 3.281724783183269e-07\n",
      "vali total epoch_loss 1.0796531373813423e-05 avarage epoch_loss 8.117692762265732e-08\n",
      "Epoch: 06 | Time: 6m 25s\n",
      "\tTrain Loss: 3.28172e-07 \n",
      "\t Val. Loss: 8.11769e-08 \n",
      "train total epoch_loss 3.492584784225983e-05 avarage epoch_loss 2.626003597162393e-07\n",
      "vali total epoch_loss 1.0707270256204993e-05 avarage epoch_loss 8.050579140003754e-08\n",
      "Epoch: 07 | Time: 6m 25s\n",
      "\tTrain Loss: 2.62600e-07 \n",
      "\t Val. Loss: 8.05058e-08 \n",
      "train total epoch_loss 3.0084294635912556e-05 avarage epoch_loss 2.2619770402941773e-07\n",
      "vali total epoch_loss 1.0677058519092952e-05 avarage epoch_loss 8.02786354819019e-08\n",
      "Epoch: 08 | Time: 6m 26s\n",
      "\tTrain Loss: 2.26198e-07 \n",
      "\t Val. Loss: 8.02786e-08 \n",
      "train total epoch_loss 2.7130292693300362e-05 avarage epoch_loss 2.039871631075215e-07\n",
      "vali total epoch_loss 1.0676672083320682e-05 avarage epoch_loss 8.027572994977956e-08\n",
      "Epoch: 09 | Time: 6m 24s\n",
      "\tTrain Loss: 2.03987e-07 \n",
      "\t Val. Loss: 8.02757e-08 \n",
      "train total epoch_loss 2.5214559542519055e-05 avarage epoch_loss 1.8958315445503048e-07\n",
      "vali total epoch_loss 1.067913119712216e-05 avarage epoch_loss 8.029421952723429e-08\n",
      "Epoch: 10 | Time: 6m 31s\n",
      "\tTrain Loss: 1.89583e-07 \n",
      "\t Val. Loss: 8.02942e-08 \n",
      "train total epoch_loss 2.3897540465611655e-05 avarage epoch_loss 1.7968075538053875e-07\n",
      "vali total epoch_loss 1.067058649084629e-05 avarage epoch_loss 8.022997361538564e-08\n",
      "Epoch: 11 | Time: 6m 29s\n",
      "\tTrain Loss: 1.79681e-07 \n",
      "\t Val. Loss: 8.02300e-08 \n",
      "train total epoch_loss 2.2978120426841997e-05 avarage epoch_loss 1.727678227582105e-07\n",
      "vali total epoch_loss 1.0675688297823172e-05 avarage epoch_loss 8.026833306633964e-08\n",
      "Epoch: 12 | Time: 6m 26s\n",
      "\tTrain Loss: 1.72768e-07 \n",
      "\t Val. Loss: 8.02683e-08 \n",
      "train total epoch_loss 2.231244791772724e-05 avarage epoch_loss 1.6776276629870105e-07\n",
      "vali total epoch_loss 1.0668841792238482e-05 avarage epoch_loss 8.021685558074047e-08\n",
      "Epoch: 13 | Time: 6m 26s\n",
      "\tTrain Loss: 1.67763e-07 \n",
      "\t Val. Loss: 8.02169e-08 \n",
      "train total epoch_loss 2.180905199367089e-05 avarage epoch_loss 1.639778345388789e-07\n",
      "vali total epoch_loss 1.0668709194305848e-05 avarage epoch_loss 8.021585860380337e-08\n",
      "Epoch: 14 | Time: 6m 31s\n",
      "\tTrain Loss: 1.63978e-07 \n",
      "\t Val. Loss: 8.02159e-08 \n",
      "train total epoch_loss 2.142373609359538e-05 avarage epoch_loss 1.6108072250823595e-07\n",
      "vali total epoch_loss 1.0663868557969636e-05 avarage epoch_loss 8.017946284187697e-08\n",
      "Epoch: 15 | Time: 6m 27s\n",
      "\tTrain Loss: 1.61081e-07 \n",
      "\t Val. Loss: 8.01795e-08 \n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "53e075add4fc865efaed3001cae69f5b66291fd877e6c0fafb5013552ba051ca"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}