{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#from torchtext.datasets import Multi30k\n",
    "#from torchtext.data import Field, BucketIterator\n",
    "\n",
    "#import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self,data = None,src_len = 20,trg_len=26):\n",
    "        self.data = data\n",
    "        self.data_lengths = len(data)\n",
    "        self.src_len = src_len\n",
    "        self.trg_len = trg_len\n",
    "    def __getitem__(self,index):\n",
    "        data=self.data[index]\n",
    "        src_data = data[0:self.src_len]\n",
    "        trg_data = data[self.src_len:self.trg_len+self.src_len]\n",
    "        return src_data,trg_data\n",
    "    def __len__(self):\n",
    "        return self.data_lengths\n",
    "\n",
    "def dataset_iter(trDataX ,trDataY):\n",
    "    trData = pd.concat([trDataX, trDataY], axis=1).to_numpy()\n",
    "    trData = trData[:,:,np.newaxis]\n",
    "    train_data, validate_data = np.split(trData, [int(.5*len(trData))])\n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset=Dataset(train_data,src_len = 20,trg_len=26),batch_size=BATCHSIZE)\n",
    "    validate_data_loader = torch.utils.data.DataLoader(dataset=Dataset(validate_data,src_len = 20,trg_len=26),batch_size=BATCHSIZE)\n",
    "    return train_data_loader,validate_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        #self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        embedded = self.dropout(src)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        #self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.rnn = nn.LSTM(output_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        input_ = input_.float().unsqueeze(0)\n",
    "        #print(\"decode input shape\",input_.shape)\n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(input))\n",
    "        embedded = self.dropout(input_)\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        #prediction = self.fc_out(output.squeeze(0)).unsqueeze(-1)\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #print(prediction.shape)\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        #print(\"trg_len\",trg.shape[0],\"batch_size\",trg.shape[1])\n",
    "        trg_feature_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_feature_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        \n",
    "        hidden, cell = self.encoder(src[0:-1])\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input_ = src[-1]\n",
    "        output, hidden, cell = self.decoder(input_, hidden, cell)\n",
    "        \n",
    "        #print(input.shape)\n",
    "        for t in range(0, trg_len):\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            #top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            #print(trg[t].shape,output.unsqueeze(-1).shape)\n",
    "            input_ = trg[t] if teacher_force else output\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input_, hidden, cell)\n",
    "            \n",
    "            #print(\"output.shape\",output.shape)[20000, 1]\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch[0].permute(1,0,2).float().to(device)\n",
    "        trg = batch[1].permute(1,0,2).float().to(device)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #print(src.shape,trg.shape)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        #print(output.shape,trg.shape)\n",
    "        #output_dim = output.shape[-1]\n",
    "        #if i%50 == 0:\n",
    "        #    print(\"output[0],trg[0]\",f'{output[0].sum():.8f}',f'{trg[0].sum():.8f}')    \n",
    "        #    print(\"output[10],trg[10]\",f'{output[10].sum():.8f}',f'{trg[10].sum():.8f}')  \n",
    "        #    print(\"output[25],trg[25]\",f'{output[25].sum():.8f}',f'{trg[25].sum():.8f}')  \n",
    "        \n",
    "        batchsize = trg.shape[1]\n",
    "        \n",
    "        #output = output[1:].view(-1)\n",
    "        output = output.permute(1,0,2).reshape(batchsize,-1)\n",
    "        \n",
    "        #trg = trg[1:].view(-1)\n",
    "        trg = trg.permute(1,0,2).reshape(batchsize,-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(\"train total epoch_loss\",epoch_loss,\"avarage epoch_loss\",epoch_loss / len(iterator))    \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch[0].permute(1,0,2).float().cuda()\n",
    "            trg = batch[1].permute(1,0,2).float().cuda()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            #$print(output[1],trg[1])\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "            #if i%50 == 0:\n",
    "                #print(\"output[0].sum(),trg[0].sum()\",output[0].sum(),trg[0].sum())\n",
    " \n",
    "            batchsize = trg.shape[1]\n",
    "            \n",
    "            #output = output[1:].view(-1)\n",
    "            output = output.permute(1,0,2).reshape(batchsize,-1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #trg = trg[1:].view(-1)\n",
    "            trg = trg.permute(1,0,2).reshape(batchsize,-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "    print(\"vali total epoch_loss\",epoch_loss,\"avarage epoch_loss\",epoch_loss / len(iterator)) \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "CITY = 1\n",
    "BATCHSIZE = 40000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "trDataX  = pd.read_csv(\"fold{}_city{}_trainX.csv\".format(FOLD,CITY),header=None)\n",
    "trDataY  = pd.read_csv(\"fold{}_city{}_trainY.csv\".format(FOLD,CITY),header=None)\n",
    "train_iterator,valid_iterator = dataset_iter(trDataX,trDataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([19, 40000, 1]) torch.Size([40000, 1])\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    if i ==0:\n",
    "        print(len(batch),batch[0].permute(1,0,2)[0:-1].shape,batch[0].permute(1,0,2)[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 100,929 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#model init\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 64\n",
    "#HID_DIM = 64\n",
    "\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total epoch_loss 0.0007740396222288837 avarage epoch_loss 1.2689174134899732e-05\n",
      "vali total epoch_loss 1.4792493104209825e-05 avarage epoch_loss 2.4249988695425945e-07\n",
      "Epoch: 01 | Time: 3m 0s\n",
      "\tTrain Loss: 1.26892e-05 \n",
      "\t Val. Loss: 2.42500e-07 \n",
      "train total epoch_loss 7.161217786233465e-05 avarage epoch_loss 1.173970128890732e-06\n",
      "vali total epoch_loss 7.216816989341623e-06 avarage epoch_loss 1.1830847523510858e-07\n",
      "Epoch: 02 | Time: 3m 0s\n",
      "\tTrain Loss: 1.17397e-06 \n",
      "\t Val. Loss: 1.18308e-07 \n",
      "train total epoch_loss 3.2005980273197565e-05 avarage epoch_loss 5.246882011999601e-07\n",
      "vali total epoch_loss 7.056328115595534e-06 avarage epoch_loss 1.1567751009173006e-07\n",
      "Epoch: 03 | Time: 3m 0s\n",
      "\tTrain Loss: 5.24688e-07 \n",
      "\t Val. Loss: 1.15678e-07 \n",
      "train total epoch_loss 2.1409443078823642e-05 avarage epoch_loss 3.509744767020269e-07\n",
      "vali total epoch_loss 6.994519210934413e-06 avarage epoch_loss 1.1466424935958055e-07\n",
      "Epoch: 04 | Time: 3m 0s\n",
      "\tTrain Loss: 3.50974e-07 \n",
      "\t Val. Loss: 1.14664e-07 \n",
      "train total epoch_loss 1.770674357715052e-05 avarage epoch_loss 2.9027448487132e-07\n",
      "vali total epoch_loss 6.973298674495254e-06 avarage epoch_loss 1.1431637171303695e-07\n",
      "Epoch: 05 | Time: 3m 4s\n",
      "\tTrain Loss: 2.90274e-07 \n",
      "\t Val. Loss: 1.14316e-07 \n",
      "train total epoch_loss 1.6095456203402136e-05 avarage epoch_loss 2.6385993776069077e-07\n",
      "vali total epoch_loss 6.9627516623427255e-06 avarage epoch_loss 1.1414346987447091e-07\n",
      "Epoch: 06 | Time: 3m 0s\n",
      "\tTrain Loss: 2.63860e-07 \n",
      "\t Val. Loss: 1.14143e-07 \n",
      "train total epoch_loss 1.525667289570265e-05 avarage epoch_loss 2.501093917328303e-07\n",
      "vali total epoch_loss 6.9577477148641265e-06 avarage epoch_loss 1.1406143794859224e-07\n",
      "Epoch: 07 | Time: 3m 0s\n",
      "\tTrain Loss: 2.50109e-07 \n",
      "\t Val. Loss: 1.14061e-07 \n",
      "train total epoch_loss 1.4770163360822153e-05 avarage epoch_loss 2.421338255872484e-07\n",
      "vali total epoch_loss 6.955786140849796e-06 avarage epoch_loss 1.1402928099753763e-07\n",
      "Epoch: 08 | Time: 2m 59s\n",
      "\tTrain Loss: 2.42134e-07 \n",
      "\t Val. Loss: 1.14029e-07 \n",
      "train total epoch_loss 1.447657005826386e-05 avarage epoch_loss 2.3732082062727638e-07\n",
      "vali total epoch_loss 6.953610260040932e-06 avarage epoch_loss 1.1399361082034315e-07\n",
      "Epoch: 09 | Time: 2m 59s\n",
      "\tTrain Loss: 2.37321e-07 \n",
      "\t Val. Loss: 1.13994e-07 \n",
      "train total epoch_loss 1.428412990378547e-05 avarage epoch_loss 2.3416606399648312e-07\n",
      "vali total epoch_loss 6.952758198508491e-06 avarage epoch_loss 1.1397964259849985e-07\n",
      "Epoch: 10 | Time: 3m 5s\n",
      "\tTrain Loss: 2.34166e-07 \n",
      "\t Val. Loss: 1.13980e-07 \n",
      "train total epoch_loss 1.4153136234540398e-05 avarage epoch_loss 2.3201862679574423e-07\n",
      "vali total epoch_loss 6.953774324358619e-06 avarage epoch_loss 1.1399630039932163e-07\n",
      "Epoch: 11 | Time: 2m 59s\n",
      "\tTrain Loss: 2.32019e-07 \n",
      "\t Val. Loss: 1.13996e-07 \n",
      "train total epoch_loss 1.4056062383360768e-05 avarage epoch_loss 2.304272521862421e-07\n",
      "vali total epoch_loss 6.952717868102809e-06 avarage epoch_loss 1.1397898144430834e-07\n",
      "Epoch: 12 | Time: 3m 1s\n",
      "\tTrain Loss: 2.30427e-07 \n",
      "\t Val. Loss: 1.13979e-07 \n",
      "train total epoch_loss 1.3984167125613567e-05 avarage epoch_loss 2.292486414035011e-07\n",
      "vali total epoch_loss 6.953898513017975e-06 avarage epoch_loss 1.139983362789832e-07\n",
      "Epoch: 13 | Time: 2m 59s\n",
      "\tTrain Loss: 2.29249e-07 \n",
      "\t Val. Loss: 1.13998e-07 \n",
      "train total epoch_loss 1.3927653192524758e-05 avarage epoch_loss 2.2832218348401244e-07\n",
      "vali total epoch_loss 6.953513995711091e-06 avarage epoch_loss 1.1399203271657526e-07\n",
      "Epoch: 14 | Time: 3m 0s\n",
      "\tTrain Loss: 2.28322e-07 \n",
      "\t Val. Loss: 1.13992e-07 \n",
      "train total epoch_loss 1.3885546664482717e-05 avarage epoch_loss 2.2763191253250358e-07\n",
      "vali total epoch_loss 6.953565055312083e-06 avarage epoch_loss 1.1399286975921447e-07\n",
      "Epoch: 15 | Time: 3m 0s\n",
      "\tTrain Loss: 2.27632e-07 \n",
      "\t Val. Loss: 1.13993e-07 \n"
     ]
    }
   ],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'fold{}-city{}-model.pt'.format(FOLD,CITY))\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5e} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5e} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1\n",
    "CITY = 1\n",
    "BATCHSIZE = 40000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "trDataX  = pd.read_csv(\"fold{}_city{}_trainX.csv\".format(FOLD,CITY),header=None)\n",
    "trDataY  = pd.read_csv(\"fold{}_city{}_trainY.csv\".format(FOLD,CITY),header=None)\n",
    "train_iterator,valid_iterator = dataset_iter(trDataX,trDataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([19, 40000, 1]) torch.Size([40000, 1])\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    if i ==0:\n",
    "        print(len(batch),batch[0].permute(1,0,2)[0:-1].shape,batch[0].permute(1,0,2)[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 100,929 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#model init\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 64\n",
    "#HID_DIM = 64\n",
    "\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total epoch_loss 0.0007124128814552932 avarage epoch_loss 7.344462695415394e-06\n",
      "vali total epoch_loss 1.078680996613457e-05 avarage epoch_loss 1.1120422645499556e-07\n",
      "Epoch: 01 | Time: 4m 46s\n",
      "\tTrain Loss: 7.34446e-06 \n",
      "\t Val. Loss: 1.11204e-07 \n",
      "train total epoch_loss 4.266350902071281e-05 avarage epoch_loss 4.3982998990425574e-07\n",
      "vali total epoch_loss 1.0433172178636596e-05 avarage epoch_loss 1.0755847606841851e-07\n",
      "Epoch: 02 | Time: 4m 57s\n",
      "\tTrain Loss: 4.39830e-07 \n",
      "\t Val. Loss: 1.07558e-07 \n",
      "train total epoch_loss 2.5893204139038062e-05 avarage epoch_loss 2.669402488560625e-07\n",
      "vali total epoch_loss 1.0429255240751445e-05 avarage epoch_loss 1.0751809526547881e-07\n",
      "Epoch: 03 | Time: 4m 45s\n",
      "\tTrain Loss: 2.66940e-07 \n",
      "\t Val. Loss: 1.07518e-07 \n",
      "train total epoch_loss 2.1655733945635802e-05 avarage epoch_loss 2.23254989130266e-07\n",
      "vali total epoch_loss 1.0426219745340859e-05 avarage epoch_loss 1.0748680149835937e-07\n",
      "Epoch: 04 | Time: 5m 10s\n",
      "\tTrain Loss: 2.23255e-07 \n",
      "\t Val. Loss: 1.07487e-07 \n",
      "train total epoch_loss 1.996905511703062e-05 avarage epoch_loss 2.058665475982538e-07\n",
      "vali total epoch_loss 1.0422541279808684e-05 avarage epoch_loss 1.074488791732854e-07\n",
      "Epoch: 05 | Time: 4m 49s\n",
      "\tTrain Loss: 2.05867e-07 \n",
      "\t Val. Loss: 1.07449e-07 \n",
      "train total epoch_loss 1.913225264615903e-05 avarage epoch_loss 1.972397180016395e-07\n",
      "vali total epoch_loss 1.042068474532698e-05 avarage epoch_loss 1.0742973964254619e-07\n",
      "Epoch: 06 | Time: 4m 47s\n",
      "\tTrain Loss: 1.97240e-07 \n",
      "\t Val. Loss: 1.07430e-07 \n",
      "train total epoch_loss 1.8663422778786298e-05 avarage epoch_loss 1.9240642039985873e-07\n",
      "vali total epoch_loss 1.0419169299780151e-05 avarage epoch_loss 1.0741411649257888e-07\n",
      "Epoch: 07 | Time: 4m 50s\n",
      "\tTrain Loss: 1.92406e-07 \n",
      "\t Val. Loss: 1.07414e-07 \n",
      "train total epoch_loss 1.837364236934036e-05 avarage epoch_loss 1.8941899349835423e-07\n",
      "vali total epoch_loss 1.0418354975172406e-05 avarage epoch_loss 1.0740572139352995e-07\n",
      "Epoch: 08 | Time: 4m 46s\n",
      "\tTrain Loss: 1.89419e-07 \n",
      "\t Val. Loss: 1.07406e-07 \n",
      "train total epoch_loss 1.8183046982755968e-05 avarage epoch_loss 1.8745409260573163e-07\n",
      "vali total epoch_loss 1.0417691839847976e-05 avarage epoch_loss 1.0739888494688635e-07\n",
      "Epoch: 09 | Time: 4m 51s\n",
      "\tTrain Loss: 1.87454e-07 \n",
      "\t Val. Loss: 1.07399e-07 \n",
      "train total epoch_loss 1.805127335785528e-05 avarage epoch_loss 1.8609560162737402e-07\n",
      "vali total epoch_loss 1.0417803864015696e-05 avarage epoch_loss 1.0740003983521336e-07\n",
      "Epoch: 10 | Time: 4m 47s\n",
      "\tTrain Loss: 1.86096e-07 \n",
      "\t Val. Loss: 1.07400e-07 \n",
      "train total epoch_loss 1.795762529610556e-05 avarage epoch_loss 1.851301576918099e-07\n",
      "vali total epoch_loss 1.0417214035385314e-05 avarage epoch_loss 1.0739395912768365e-07\n",
      "Epoch: 11 | Time: 4m 50s\n",
      "\tTrain Loss: 1.85130e-07 \n",
      "\t Val. Loss: 1.07394e-07 \n",
      "train total epoch_loss 1.788456717832787e-05 avarage epoch_loss 1.8437698121987495e-07\n",
      "vali total epoch_loss 1.0417034417287141e-05 avarage epoch_loss 1.0739210739471279e-07\n",
      "Epoch: 12 | Time: 5m 8s\n",
      "\tTrain Loss: 1.84377e-07 \n",
      "\t Val. Loss: 1.07392e-07 \n",
      "train total epoch_loss 1.7830729099443943e-05 avarage epoch_loss 1.8382194947880352e-07\n",
      "vali total epoch_loss 1.041685783320645e-05 avarage epoch_loss 1.0739028694027268e-07\n",
      "Epoch: 13 | Time: 4m 49s\n",
      "\tTrain Loss: 1.83822e-07 \n",
      "\t Val. Loss: 1.07390e-07 \n",
      "train total epoch_loss 1.7787470802943517e-05 avarage epoch_loss 1.833759876592115e-07\n",
      "vali total epoch_loss 1.0416703283055995e-05 avarage epoch_loss 1.0738869363975252e-07\n",
      "Epoch: 14 | Time: 4m 47s\n",
      "\tTrain Loss: 1.83376e-07 \n",
      "\t Val. Loss: 1.07389e-07 \n",
      "train total epoch_loss 1.7751347378691662e-05 avarage epoch_loss 1.8300358122362538e-07\n",
      "vali total epoch_loss 1.0416690017223118e-05 avarage epoch_loss 1.0738855687858884e-07\n",
      "Epoch: 15 | Time: 4m 48s\n",
      "\tTrain Loss: 1.83004e-07 \n",
      "\t Val. Loss: 1.07389e-07 \n"
     ]
    }
   ],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'fold{}-city{}-model.pt'.format(FOLD,CITY))\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5e} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5e} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 2\n",
    "CITY = 1\n",
    "BATCHSIZE = 40000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "trDataX  = pd.read_csv(\"fold{}_city{}_trainX.csv\".format(FOLD,CITY),header=None)\n",
    "trDataY  = pd.read_csv(\"fold{}_city{}_trainY.csv\".format(FOLD,CITY),header=None)\n",
    "train_iterator,valid_iterator = dataset_iter(trDataX,trDataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([19, 40000, 1]) torch.Size([40000, 1])\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_iterator):\n",
    "    if i ==0:\n",
    "        print(len(batch),batch[0].permute(1,0,2)[0:-1].shape,batch[0].permute(1,0,2)[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 100,929 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#model init\n",
    "\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 1\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 64\n",
    "#HID_DIM = 64\n",
    "\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "#criterion = nn.MSELoss(reduction='sum')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total epoch_loss 0.014091146198552451 avarage epoch_loss 0.00010594846765828911\n",
      "vali total epoch_loss 2.4075391849009975e-05 avarage epoch_loss 1.8101798382714266e-07\n",
      "Epoch: 01 | Time: 6m 31s\n",
      "\tTrain Loss: 1.05948e-04 \n",
      "\t Val. Loss: 1.81018e-07 \n",
      "train total epoch_loss 0.0003882422206515912 avarage epoch_loss 2.9191144409894073e-06\n",
      "vali total epoch_loss 1.8832104984767284e-05 avarage epoch_loss 1.4159477432155853e-07\n",
      "Epoch: 02 | Time: 6m 33s\n",
      "\tTrain Loss: 2.91911e-06 \n",
      "\t Val. Loss: 1.41595e-07 \n",
      "train total epoch_loss 0.00018753318340714031 avarage epoch_loss 1.4100239353920324e-06\n",
      "vali total epoch_loss 1.584567265666692e-05 avarage epoch_loss 1.1914039591478887e-07\n",
      "Epoch: 03 | Time: 6m 33s\n",
      "\tTrain Loss: 1.41002e-06 \n",
      "\t Val. Loss: 1.19140e-07 \n",
      "train total epoch_loss 0.0001018437492348312 avarage epoch_loss 7.657424754498586e-07\n",
      "vali total epoch_loss 1.4270594917320523e-05 avarage epoch_loss 1.0729770614526708e-07\n",
      "Epoch: 04 | Time: 6m 32s\n",
      "\tTrain Loss: 7.65742e-07 \n",
      "\t Val. Loss: 1.07298e-07 \n",
      "train total epoch_loss 6.421975862735962e-05 avarage epoch_loss 4.828553280252603e-07\n",
      "vali total epoch_loss 1.3566987050239732e-05 avarage epoch_loss 1.0200742143037392e-07\n",
      "Epoch: 05 | Time: 6m 34s\n",
      "\tTrain Loss: 4.82855e-07 \n",
      "\t Val. Loss: 1.02007e-07 \n",
      "train total epoch_loss 4.680107139165557e-05 avarage epoch_loss 3.5188775482447796e-07\n",
      "vali total epoch_loss 1.3275754689345831e-05 avarage epoch_loss 9.981770443117167e-08\n",
      "Epoch: 06 | Time: 6m 32s\n",
      "\tTrain Loss: 3.51888e-07 \n",
      "\t Val. Loss: 9.98177e-08 \n",
      "train total epoch_loss 3.807360766927559e-05 avarage epoch_loss 2.862677268366586e-07\n",
      "vali total epoch_loss 1.3186520085639586e-05 avarage epoch_loss 9.914676756119989e-08\n",
      "Epoch: 07 | Time: 6m 36s\n",
      "\tTrain Loss: 2.86268e-07 \n",
      "\t Val. Loss: 9.91468e-08 \n",
      "train total epoch_loss 3.323691537104878e-05 avarage epoch_loss 2.4990161933119383e-07\n",
      "vali total epoch_loss 1.3156135814540448e-05 avarage epoch_loss 9.891831439504096e-08\n",
      "Epoch: 08 | Time: 6m 32s\n",
      "\tTrain Loss: 2.49902e-07 \n",
      "\t Val. Loss: 9.89183e-08 \n",
      "train total epoch_loss 3.0279683073786146e-05 avarage epoch_loss 2.2766679002846727e-07\n",
      "vali total epoch_loss 1.31559818896676e-05 avarage epoch_loss 9.891715706516993e-08\n",
      "Epoch: 09 | Time: 6m 38s\n",
      "\tTrain Loss: 2.27667e-07 \n",
      "\t Val. Loss: 9.89172e-08 \n",
      "train total epoch_loss 2.836555189844603e-05 avarage epoch_loss 2.132748263041055e-07\n",
      "vali total epoch_loss 1.3158231510601581e-05 avarage epoch_loss 9.893407150828257e-08\n",
      "Epoch: 10 | Time: 6m 34s\n",
      "\tTrain Loss: 2.13275e-07 \n",
      "\t Val. Loss: 9.89341e-08 \n",
      "train total epoch_loss 2.704865613623042e-05 avarage epoch_loss 2.0337335440774752e-07\n",
      "vali total epoch_loss 1.314977988897681e-05 avarage epoch_loss 9.887052548102864e-08\n",
      "Epoch: 11 | Time: 6m 35s\n",
      "\tTrain Loss: 2.03373e-07 \n",
      "\t Val. Loss: 9.88705e-08 \n",
      "train total epoch_loss 2.6127273784481986e-05 avarage epoch_loss 1.9644566755249613e-07\n",
      "vali total epoch_loss 1.3154825062144937e-05 avarage epoch_loss 9.890845911387171e-08\n",
      "Epoch: 12 | Time: 6m 36s\n",
      "\tTrain Loss: 1.96446e-07 \n",
      "\t Val. Loss: 9.89085e-08 \n",
      "train total epoch_loss 2.546219796784044e-05 avarage epoch_loss 1.914450975025597e-07\n",
      "vali total epoch_loss 1.3148093749748568e-05 avarage epoch_loss 9.885784774247043e-08\n",
      "Epoch: 13 | Time: 6m 35s\n",
      "\tTrain Loss: 1.91445e-07 \n",
      "\t Val. Loss: 9.88578e-08 \n",
      "train total epoch_loss 2.495876627506277e-05 avarage epoch_loss 1.8765989680498323e-07\n",
      "vali total epoch_loss 1.3147703782578901e-05 avarage epoch_loss 9.885491565848798e-08\n",
      "Epoch: 14 | Time: 6m 34s\n",
      "\tTrain Loss: 1.87660e-07 \n",
      "\t Val. Loss: 9.88549e-08 \n",
      "train total epoch_loss 2.457387682852641e-05 avarage epoch_loss 1.847659911919279e-07\n",
      "vali total epoch_loss 1.3142916380104452e-05 avarage epoch_loss 9.88189201511613e-08\n",
      "Epoch: 15 | Time: 6m 29s\n",
      "\tTrain Loss: 1.84766e-07 \n",
      "\t Val. Loss: 9.88189e-08 \n"
     ]
    }
   ],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    #train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'fold{}-city{}-model.pt'.format(FOLD,CITY))\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5e} ')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5e} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py37",
   "language": "python",
   "name": "zhangxz_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
