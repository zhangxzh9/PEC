{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import time\n",
    "\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "#env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_path = '/home/ubuntu/data/dataset/R3009_U5_V100/'\n",
    "UIT = pd.read_csv(data_path + 'UIT.csv')\n",
    "UIT"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>viewtime</th>\n",
       "      <th>video_type</th>\n",
       "      <th>video_format</th>\n",
       "      <th>city</th>\n",
       "      <th>city_isp</th>\n",
       "      <th>client_ip</th>\n",
       "      <th>conn_type</th>\n",
       "      <th>device_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365</td>\n",
       "      <td>3391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>1030</td>\n",
       "      <td>101001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11807</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>5779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15068</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208</td>\n",
       "      <td>4675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>1035</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5375</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1030</td>\n",
       "      <td>10202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5992</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>439</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3468</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300978</th>\n",
       "      <td>483</td>\n",
       "      <td>6831</td>\n",
       "      <td>29</td>\n",
       "      <td>2591880</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300979</th>\n",
       "      <td>158</td>\n",
       "      <td>8448</td>\n",
       "      <td>29</td>\n",
       "      <td>2591880</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23340</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300980</th>\n",
       "      <td>483</td>\n",
       "      <td>6463</td>\n",
       "      <td>29</td>\n",
       "      <td>2591940</td>\n",
       "      <td>35</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300981</th>\n",
       "      <td>158</td>\n",
       "      <td>4715</td>\n",
       "      <td>29</td>\n",
       "      <td>2591940</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23340</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300982</th>\n",
       "      <td>483</td>\n",
       "      <td>2021</td>\n",
       "      <td>29</td>\n",
       "      <td>2591940</td>\n",
       "      <td>34</td>\n",
       "      <td>1030</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300983 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          u     i  day     time  viewtime  video_type  video_format  city  \\\n",
       "0       365  3391    0        0       148        1030        101001     0   \n",
       "1       203  5779    0        0         7        1030         10203     0   \n",
       "2       208  4675    0        0        92        1035         10203     0   \n",
       "3       159   332    0        0        56        1030         10202     0   \n",
       "4        50   674    0        0       439        1030         10203     0   \n",
       "...     ...   ...  ...      ...       ...         ...           ...   ...   \n",
       "300978  483  6831   29  2591880        34        1030         10203     0   \n",
       "300979  158  8448   29  2591880        34        1030         10203     0   \n",
       "300980  483  6463   29  2591940        35        1030         10203     0   \n",
       "300981  158  4715   29  2591940        34        1030         10203     0   \n",
       "300982  483  2021   29  2591940        34        1030         10203     0   \n",
       "\n",
       "        city_isp  client_ip  conn_type  device_type  \n",
       "0              0      11807          1            2  \n",
       "1              0      15068          1            2  \n",
       "2              0       5375          1            2  \n",
       "3              0       5992          1            2  \n",
       "4              0       3468          1            2  \n",
       "...          ...        ...        ...          ...  \n",
       "300978         0      10010          1            2  \n",
       "300979         0      23340          1            2  \n",
       "300980         0      10010          1            2  \n",
       "300981         0      23340          1            2  \n",
       "300982         0      10010          1            2  \n",
       "\n",
       "[300983 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "trainUIT = UIT[UIT['day']<18]\n",
    "contentNum = len(UIT.i.drop_duplicates())\n",
    "userNum = len(UIT.u.drop_duplicates())\n",
    "contentNum,userNum,trainUIT"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000,\n",
       " 500,\n",
       "           u     i  day     time  viewtime  video_type  video_format  city  \\\n",
       " 0       365  3391    0        0       148        1030        101001     0   \n",
       " 1       203  5779    0        0         7        1030         10203     0   \n",
       " 2       208  4675    0        0        92        1035         10203     0   \n",
       " 3       159   332    0        0        56        1030         10202     0   \n",
       " 4        50   674    0        0       439        1030         10203     0   \n",
       " ...     ...   ...  ...      ...       ...         ...           ...   ...   \n",
       " 198170  264  7442   17  1555140        90        1035         10203     0   \n",
       " 198171   19  9362   17  1555140       424        1035         10203     0   \n",
       " 198172   82  9223   17  1555140        94        1037         10203     0   \n",
       " 198173   35  4164   17  1555140        22        1030         10203     0   \n",
       " 198174  239  5062   17  1555140        89        1035         10203     0   \n",
       " \n",
       "         city_isp  client_ip  conn_type  device_type  \n",
       " 0              0      11807          1            2  \n",
       " 1              0      15068          1            2  \n",
       " 2              0       5375          1            2  \n",
       " 3              0       5992          1            2  \n",
       " 4              0       3468          1            2  \n",
       " ...          ...        ...        ...          ...  \n",
       " 198170         0       7592          1            2  \n",
       " 198171         0       5938          1            2  \n",
       " 198172         0      11393          1            2  \n",
       " 198173         0       5866          1            2  \n",
       " 198174         0      23746          1            2  \n",
       " \n",
       " [198175 rows x 12 columns])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class ENV(object):\n",
    "    def __init__(self,userNum,contentNum):\n",
    "        self.userNum = userNum\n",
    "        self.contentNum =contentNum\n",
    "\n",
    "        self.r = np.zeros(shape=(userNum,contentNum),dtype=int)\n",
    "        self.p = np.full(shape=contentNum,fill_value = 1/userNum)\n",
    "        self.e = np.zeros(shape=contentNum)\n",
    "        self.S = np.ones(shape=contentNum,dtype=int)\n",
    "        self.l_edge = 0.1\n",
    "        self.l_cp = 1\n",
    "\n",
    "        self.B = np.full(shape=userNum,fill_value=10,dtype=int)\n",
    "\n",
    "        self.pipe = collections.OrderedDict()\n",
    "\n",
    "\n",
    "    #有序字典实现LRU\n",
    "    def updateEgdeCache(self,action,t):\n",
    "        for i in np.argwhere(action==1).squeeze(-1):\n",
    "            if i in self.pipe.keys():\n",
    "                self.pipe.pop(i)\n",
    "            elif len(self.pipe) >= 500:\n",
    "                self.e[self.pipe.popitem(last=False)[0]] = 0\n",
    "            self.pipe[i] = t\n",
    "            self.e[i] = 1\n",
    "\n",
    "    \n",
    "    def updateEnv(self,u,action,t):\n",
    "        \n",
    "        p_tmp = ((self.r[u] | action)-self.r[u])*(1/self.userNum) + self.p\n",
    "        self.p = np.where(p_tmp<1-1/self.userNum,p_tmp,1-1/self.userNum)\n",
    "\n",
    "        self.r[u] = self.r[u] | action\n",
    "\n",
    "        self.updateEgdeCache(action,t)\n",
    "\n",
    "    def getStatus(self):\n",
    "        return (torch.from_numpy(self.r),\n",
    "                torch.from_numpy(self.p) , \n",
    "                torch.from_numpy(self.e),\n",
    "                torch.from_numpy(self.S),\n",
    "                self.l_edge,\n",
    "                self.l_cp)\n",
    "\n",
    "    #def reset(self):\n",
    "    #    self.r = np.zeros(shape=(self.userNum,self.contentNum),dtype=int)\n",
    "    #    self.p = np.full(shape=self.contentNum,fill_value = 1/self.userNum)\n",
    "    #    self.e = np.zeros(shape=self.contentNum)\n",
    "    #    self.S = np.ones(shape=self.contentNum,dtype=int)\n",
    "    #    self.l_edge = 0.1\n",
    "    #    self.l_cp = 1\n",
    "    #    self.B = np.full(shape=self.userNum,fill_value=15,dtype=int)\n",
    "    #    self.pipe = collections.OrderedDict()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class UE_random(object):\n",
    "    def __init__(self,u,env,rewardPara):\n",
    "        self.u = u\n",
    "\n",
    "        self.W = []\n",
    "        self.v = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "\n",
    "        self.Bu = int(env.B[self.u])\n",
    "        self.contentNum = env.contentNum\n",
    "        self.userNum = env.userNum\n",
    "\n",
    "        self.r , self.p , self.e, self.S,self.l_edge, self.l_cp = env.getStatus()\n",
    "\n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.lastAction = self.action\n",
    "\n",
    "        self.reward = 0\n",
    "        self.ALPHAh = rewardPara['alpha']\n",
    "        self.BETAo =  rewardPara['betao']\n",
    "        self.BETAl =  rewardPara['betal']\n",
    "\n",
    "    def updateViewContent(self,i):\n",
    "        self.W.append(i)\n",
    "        self.v[i] = 1\n",
    "\n",
    "    \n",
    "    def getReward(self,lastru,lastp,ru,p,i,action,S,Bu,l_edge,l_cp,e):\n",
    "\n",
    "        self.Rh = - self.ALPHAh * (torch.log(ru * p + (1-ru) * (1-p)) - torch.log(lastru * lastp + (1-lastru) * (1-lastp))).sum()\n",
    "\n",
    "        self.Ro =   self.BETAo * action[i] * (S[i] / Bu + ( e[i] * l_edge + ( 1-e[i] ) * l_cp ) / S[i])\n",
    "\n",
    "        self.Rl =   self.BETAl * ( ( 1 - action[i] )  * ( l_cp - ( e[i] * l_edge + ( 1 - e[i] ) * l_cp ) ) ) / S[i]\n",
    "\n",
    "        #self.Rh[i] = self.Rh[i] + self.Ro + self.Rl\n",
    "\n",
    "        return  self.Rh+self.Ro+self.Rl\n",
    "\n",
    "    def selectAction(self,env,uit):\n",
    "\n",
    "\n",
    "        self.lastAction = self.action\n",
    "        self.lastp = self.p\n",
    "        self.lastr = self.r\n",
    "\n",
    "        self.updateViewContent(uit[1])\n",
    "        self.r , self.p , self.e, self.S, self.l_edge, self.l_cp = env.getStatus()\n",
    "        \n",
    "        self.reward = self.getReward(self.lastr[self.u],self.lastp,self.r[self.u],self.p,self.W[-1],self.lastAction,self.S,self.Bu,self.l_edge,self.l_cp,self.e)\n",
    "        \n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.action[self.W[-1]] = 1\n",
    "\n",
    "        actionIndex = list(torch.randint(0,self.contentNum,(self.Bu,)))\n",
    "        \n",
    "        if self.W[-1] not in actionIndex:\n",
    "            actionIndex.pop()\n",
    "        for index in actionIndex:\n",
    "            self.action[index] = 1\n",
    "\n",
    "        env.updateEnv(self.u,self.action.numpy(),uit[2])\n",
    "\n",
    "        return self.action"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "num_episodes = 1\n",
    "TARGET_UPDATE = 1\n",
    "bestReward =  float(\"-inf\")\n",
    "\n",
    "env = ENV(userNum,contentNum)\n",
    "UEs = {}\n",
    "sumReward = np.zeros(3)\n",
    "loss = 0\n",
    "UEHit = np.zeros(userNum)\n",
    "edgeHit = 0\n",
    "\n",
    "rewardPara = {\"alpha\":1,\"betao\":0.5,\"betal\":0.5}\n",
    "\n",
    "sumHitrate = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "UEHitrate = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "edgeHitrate = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "privacyReduction = np.zeros(UIT.shape[0]// 10000 +2)\n",
    "\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    for index,trace in UIT.iterrows():\n",
    "        uit = trace.to_numpy()\n",
    "        if uit[0] not in UEs:\n",
    "            UEs[uit[0]] = UE_random(uit[0],env,rewardPara)\n",
    "\n",
    "        ue = UEs[uit[0]]\n",
    "        \n",
    "        actionIndex = np.argwhere(ue.lastAction)\n",
    "        if uit[1] in actionIndex:\n",
    "            UEHit[uit[0]] += 1\n",
    "        elif uit[1] in env.pipe.keys():\n",
    "            edgeHit += 1\n",
    "\n",
    "        ue.selectAction(env,uit)\n",
    "\n",
    "        sumReward[0] += float(ue.Rh)\n",
    "        sumReward[1] += float(ue.Rl)\n",
    "        sumReward[2] += float(ue.Ro)\n",
    "\n",
    "        if index % 10000 == 0 :\n",
    "            psi = 0\n",
    "            p = torch.from_numpy(env.p)\n",
    "            for u in UEs:\n",
    "                psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "            print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "            print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "            print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "            print()\n",
    "            sumHitrate[int(index // 10000)]   = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "            UEHitrate [int(index // 10000)]   = round(UEHit.sum()/(index+1),5)\n",
    "            edgeHitrate [int(index // 10000)] = round(edgeHit/(index+1),5)\n",
    "            privacyReduction [int(index // 10000)] = round(float(psi)/len(UEs),5)\n",
    "    psi = 0\n",
    "    p = torch.from_numpy(env.p)\n",
    "    for u in UEs:\n",
    "        psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "    print()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "    print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "    print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    sumHitrate [int(round(index / 10000,0))]  = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "    UEHitrate  [int(round(index / 10000,0))]  = round(UEHit.sum()/(index+1),5)\n",
    "    edgeHitrate[int(round(index / 10000,0))]  = round(edgeHit/(index+1),5)\n",
    "    privacyReduction [int(round(index / 10000,0))] = round(float(psi)/len(UEs),5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Time: Sun Sep 19 13:50:48 2021 Episode: 0   Index: 0   Loss: 0.0 --\n",
      "Reward: [0. 0. 0.] total reward: 0.0\n",
      "UEHitrate: 0.0  edgeHitrate 0.0 sumHitrate 0.0  privacy: 2.94295\n",
      "\n",
      "--Time: Sun Sep 19 13:51:01 2021 Episode: 0   Index: 10000   Loss: 0.0 --\n",
      "Reward: [-3.55515e+00  4.43200e-02  1.63000e-03] total reward: -3.5092\n",
      "UEHitrate: 0.0021  edgeHitrate 0.09869 sumHitrate 0.10079  privacy: 3.56311\n",
      "\n",
      "--Time: Sun Sep 19 13:51:14 2021 Episode: 0   Index: 20000   Loss: 0.0 --\n",
      "Reward: [-2.99492e+00  4.90000e-02  2.05000e-03] total reward: -2.94387\n",
      "UEHitrate: 0.0024  edgeHitrate 0.10889 sumHitrate 0.11129  privacy: 3.31123\n",
      "\n",
      "--Time: Sun Sep 19 13:51:27 2021 Episode: 0   Index: 30000   Loss: 0.0 --\n",
      "Reward: [-2.5363e+00  4.5720e-02  2.2500e-03] total reward: -2.48833\n",
      "UEHitrate: 0.00273  edgeHitrate 0.1019 sumHitrate 0.10463  privacy: 3.08386\n",
      "\n",
      "--Time: Sun Sep 19 13:51:40 2021 Episode: 0   Index: 40000   Loss: 0.0 --\n",
      "Reward: [-2.28306  0.04521  0.00231] total reward: -2.23553\n",
      "UEHitrate: 0.00302  edgeHitrate 0.1007 sumHitrate 0.10372  privacy: 2.91028\n",
      "\n",
      "--Time: Sun Sep 19 13:51:53 2021 Episode: 0   Index: 50000   Loss: 0.0 --\n",
      "Reward: [-2.06904  0.04515  0.00243] total reward: -2.02145\n",
      "UEHitrate: 0.0033  edgeHitrate 0.10064 sumHitrate 0.10394  privacy: 2.74719\n",
      "\n",
      "--Time: Sun Sep 19 13:52:06 2021 Episode: 0   Index: 60000   Loss: 0.0 --\n",
      "Reward: [-1.89852  0.04406  0.00246] total reward: -1.852\n",
      "UEHitrate: 0.00315  edgeHitrate 0.0982 sumHitrate 0.10135  privacy: 2.62383\n",
      "\n",
      "--Time: Sun Sep 19 13:52:19 2021 Episode: 0   Index: 70000   Loss: 0.0 --\n",
      "Reward: [-1.74142  0.04265  0.00239] total reward: -1.69638\n",
      "UEHitrate: 0.00314  edgeHitrate 0.095 sumHitrate 0.09814  privacy: 2.52184\n",
      "\n",
      "--Time: Sun Sep 19 13:52:31 2021 Episode: 0   Index: 80000   Loss: 0.0 --\n",
      "Reward: [-1.6483   0.04207  0.0024 ] total reward: -1.60383\n",
      "UEHitrate: 0.0031  edgeHitrate 0.09379 sumHitrate 0.09689  privacy: 2.42206\n",
      "\n",
      "--Time: Sun Sep 19 13:52:44 2021 Episode: 0   Index: 90000   Loss: 0.0 --\n",
      "Reward: [-1.5278   0.0419   0.00245] total reward: -1.48344\n",
      "UEHitrate: 0.00324  edgeHitrate 0.09331 sumHitrate 0.09655  privacy: 2.32575\n",
      "\n",
      "--Time: Sun Sep 19 13:52:57 2021 Episode: 0   Index: 100000   Loss: 0.0 --\n",
      "Reward: [-1.40588  0.04155  0.00244] total reward: -1.36189\n",
      "UEHitrate: 0.00327  edgeHitrate 0.09254 sumHitrate 0.09581  privacy: 2.2257\n",
      "\n",
      "--Time: Sun Sep 19 13:53:10 2021 Episode: 0   Index: 110000   Loss: 0.0 --\n",
      "Reward: [-1.29213  0.04146  0.00248] total reward: -1.24819\n",
      "UEHitrate: 0.0033  edgeHitrate 0.09246 sumHitrate 0.09576  privacy: 2.14044\n",
      "\n",
      "--Time: Sun Sep 19 13:53:23 2021 Episode: 0   Index: 120000   Loss: 0.0 --\n",
      "Reward: [-1.17578  0.04138  0.00249] total reward: -1.13192\n",
      "UEHitrate: 0.00341  edgeHitrate 0.09232 sumHitrate 0.09573  privacy: 2.07087\n",
      "\n",
      "--Time: Sun Sep 19 13:53:36 2021 Episode: 0   Index: 130000   Loss: 0.0 --\n",
      "Reward: [-1.10111  0.04084  0.00257] total reward: -1.05771\n",
      "UEHitrate: 0.0036  edgeHitrate 0.09118 sumHitrate 0.09478  privacy: 2.00069\n",
      "\n",
      "--Time: Sun Sep 19 13:53:49 2021 Episode: 0   Index: 140000   Loss: 0.0 --\n",
      "Reward: [-0.99001  0.04097  0.00263] total reward: -0.94642\n",
      "UEHitrate: 0.00364  edgeHitrate 0.09149 sumHitrate 0.09513  privacy: 1.9371\n",
      "\n",
      "--Time: Sun Sep 19 13:54:01 2021 Episode: 0   Index: 150000   Loss: 0.0 --\n",
      "Reward: [-0.93693  0.04099  0.00266] total reward: -0.89328\n",
      "UEHitrate: 0.00371  edgeHitrate 0.09151 sumHitrate 0.09521  privacy: 1.87852\n",
      "\n",
      "--Time: Sun Sep 19 13:54:14 2021 Episode: 0   Index: 160000   Loss: 0.0 --\n",
      "Reward: [-0.8694   0.0406   0.00275] total reward: -0.82604\n",
      "UEHitrate: 0.00371  edgeHitrate 0.09066 sumHitrate 0.09436  privacy: 1.81909\n",
      "\n",
      "--Time: Sun Sep 19 13:54:27 2021 Episode: 0   Index: 170000   Loss: 0.0 --\n",
      "Reward: [-0.8202   0.04068  0.00277] total reward: -0.77675\n",
      "UEHitrate: 0.00375  edgeHitrate 0.09087 sumHitrate 0.09462  privacy: 1.764\n",
      "\n",
      "--Time: Sun Sep 19 13:54:40 2021 Episode: 0   Index: 180000   Loss: 0.0 --\n",
      "Reward: [-0.75583  0.04076  0.00281] total reward: -0.71226\n",
      "UEHitrate: 0.00373  edgeHitrate 0.09107 sumHitrate 0.0948  privacy: 1.7077\n",
      "\n",
      "--Time: Sun Sep 19 13:54:53 2021 Episode: 0   Index: 190000   Loss: 0.0 --\n",
      "Reward: [-0.71675  0.04054  0.00283] total reward: -0.67337\n",
      "UEHitrate: 0.00382  edgeHitrate 0.09059 sumHitrate 0.0944  privacy: 1.6565\n",
      "\n",
      "--Time: Sun Sep 19 13:55:06 2021 Episode: 0   Index: 200000   Loss: 0.0 --\n",
      "Reward: [-0.68051  0.04064  0.00284] total reward: -0.63703\n",
      "UEHitrate: 0.0038  edgeHitrate 0.0908 sumHitrate 0.0946  privacy: 1.60888\n",
      "\n",
      "--Time: Sun Sep 19 13:55:19 2021 Episode: 0   Index: 210000   Loss: 0.0 --\n",
      "Reward: [-0.63215  0.04077  0.00288] total reward: -0.58849\n",
      "UEHitrate: 0.00387  edgeHitrate 0.09111 sumHitrate 0.09498  privacy: 1.56053\n",
      "\n",
      "--Time: Sun Sep 19 13:55:31 2021 Episode: 0   Index: 220000   Loss: 0.0 --\n",
      "Reward: [-0.59355  0.04056  0.00292] total reward: -0.55008\n",
      "UEHitrate: 0.00391  edgeHitrate 0.09066 sumHitrate 0.09458  privacy: 1.51605\n",
      "\n",
      "--Time: Sun Sep 19 13:55:44 2021 Episode: 0   Index: 230000   Loss: 0.0 --\n",
      "Reward: [-0.56358  0.04054  0.00293] total reward: -0.5201\n",
      "UEHitrate: 0.00396  edgeHitrate 0.09062 sumHitrate 0.09457  privacy: 1.47154\n",
      "\n",
      "--Time: Sun Sep 19 13:55:57 2021 Episode: 0   Index: 240000   Loss: 0.0 --\n",
      "Reward: [-0.52189  0.04039  0.00296] total reward: -0.47854\n",
      "UEHitrate: 0.00398  edgeHitrate 0.09025 sumHitrate 0.09424  privacy: 1.43023\n",
      "\n",
      "--Time: Sun Sep 19 13:56:10 2021 Episode: 0   Index: 250000   Loss: 0.0 --\n",
      "Reward: [-0.4945   0.04064  0.00298] total reward: -0.45088\n",
      "UEHitrate: 0.00404  edgeHitrate 0.0908 sumHitrate 0.09484  privacy: 1.39058\n",
      "\n",
      "--Time: Sun Sep 19 13:56:23 2021 Episode: 0   Index: 260000   Loss: 0.0 --\n",
      "Reward: [-0.47557  0.04049  0.00299] total reward: -0.43209\n",
      "UEHitrate: 0.00409  edgeHitrate 0.09046 sumHitrate 0.09455  privacy: 1.35325\n",
      "\n",
      "--Time: Sun Sep 19 13:56:36 2021 Episode: 0   Index: 270000   Loss: 0.0 --\n",
      "Reward: [-0.45073  0.04026  0.00301] total reward: -0.40746\n",
      "UEHitrate: 0.00415  edgeHitrate 0.08997 sumHitrate 0.09412  privacy: 1.31744\n",
      "\n",
      "--Time: Sun Sep 19 13:56:48 2021 Episode: 0   Index: 280000   Loss: 0.0 --\n",
      "Reward: [-0.44033  0.04041  0.00302] total reward: -0.39689\n",
      "UEHitrate: 0.00417  edgeHitrate 0.0903 sumHitrate 0.09448  privacy: 1.28244\n",
      "\n",
      "--Time: Sun Sep 19 13:57:01 2021 Episode: 0   Index: 290000   Loss: 0.0 --\n",
      "Reward: [-0.42491  0.04059  0.00302] total reward: -0.3813\n",
      "UEHitrate: 0.0042  edgeHitrate 0.0907 sumHitrate 0.0949  privacy: 1.2482\n",
      "\n",
      "--Time: Sun Sep 19 13:57:13 2021 Episode: 0   Index: 300000   Loss: 0.0 --\n",
      "Reward: [-0.40706  0.04062  0.00301] total reward: -0.36343\n",
      "UEHitrate: 0.00419  edgeHitrate 0.09078 sumHitrate 0.09497  privacy: 1.21612\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "--Time: Sun Sep 19 13:57:15 2021 Episode: 0   Index: 300982   Loss: 0.0 --\n",
      "Reward: [-0.40559  0.04062  0.00301] total reward: -0.36197\n",
      "UEHitrate: 0.00419  edgeHitrate 0.09077 sumHitrate 0.09497  privacy: 1.21305\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sumHitrate, UEHitrate, edgeHitrate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.     , 0.10079, 0.11129, 0.10463, 0.10372, 0.10394, 0.10135,\n",
       "        0.09814, 0.09689, 0.09655, 0.09581, 0.09576, 0.09573, 0.09478,\n",
       "        0.09513, 0.09521, 0.09436, 0.09462, 0.0948 , 0.0944 , 0.0946 ,\n",
       "        0.09498, 0.09458, 0.09457, 0.09424, 0.09484, 0.09455, 0.09412,\n",
       "        0.09448, 0.0949 , 0.09497, 0.     ]),\n",
       " array([0.     , 0.0021 , 0.0024 , 0.00273, 0.00302, 0.0033 , 0.00315,\n",
       "        0.00314, 0.0031 , 0.00324, 0.00327, 0.0033 , 0.00341, 0.0036 ,\n",
       "        0.00364, 0.00371, 0.00371, 0.00375, 0.00373, 0.00382, 0.0038 ,\n",
       "        0.00387, 0.00391, 0.00396, 0.00398, 0.00404, 0.00409, 0.00415,\n",
       "        0.00417, 0.0042 , 0.00419, 0.     ]),\n",
       " array([0.     , 0.09869, 0.10889, 0.1019 , 0.1007 , 0.10064, 0.0982 ,\n",
       "        0.095  , 0.09379, 0.09331, 0.09254, 0.09246, 0.09232, 0.09118,\n",
       "        0.09149, 0.09151, 0.09066, 0.09087, 0.09107, 0.09059, 0.0908 ,\n",
       "        0.09111, 0.09066, 0.09062, 0.09025, 0.0908 , 0.09046, 0.08997,\n",
       "        0.0903 , 0.0907 , 0.09077, 0.     ]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "privacyReduction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.94295, 3.56311, 3.31123, 3.08386, 2.91028, 2.74719, 2.62383,\n",
       "       2.52184, 2.42206, 2.32575, 2.2257 , 2.14044, 2.07087, 2.00069,\n",
       "       1.9371 , 1.87852, 1.81909, 1.764  , 1.7077 , 1.6565 , 1.60888,\n",
       "       1.56053, 1.51605, 1.47154, 1.43023, 1.39058, 1.35325, 1.31744,\n",
       "       1.28244, 1.2482 , 1.21305, 0.     ])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class UE_None(object):\n",
    "    def __init__(self,u,env,rewardPara):\n",
    "        self.u = u\n",
    "\n",
    "        self.W = []\n",
    "        self.v = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "\n",
    "        self.Bu = int(env.B[self.u])\n",
    "        self.contentNum = env.contentNum\n",
    "        self.userNum = env.userNum\n",
    "\n",
    "        self.r , self.p , self.e, self.S,self.l_edge, self.l_cp = env.getStatus()\n",
    "\n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.lastAction = self.action\n",
    "\n",
    "        self.reward = 0\n",
    "        self.ALPHAh = rewardPara['alpha']\n",
    "        self.BETAo =  rewardPara['betao']\n",
    "        self.BETAl =  rewardPara['betal']\n",
    "\n",
    "    def updateViewContent(self,i):\n",
    "        self.W.append(i)\n",
    "        self.v[i] = 1\n",
    "\n",
    "    \n",
    "    def getReward(self,lastru,lastp,ru,p,i,action,S,Bu,l_edge,l_cp,e):\n",
    "\n",
    "        self.Rh = - self.ALPHAh * (torch.log(lastru * lastp + (1-lastru) * (1-lastp)).sum() - torch.log(ru * p + (1-ru) * (1-p)).sum())\n",
    "\n",
    "        self.Ro =   self.BETAo * action[i] * (S[i] / Bu + ( e[i] * l_edge + ( 1-e[i] ) * l_cp ) / S[i])\n",
    "\n",
    "        self.Rl =   self.BETAl * ( ( 1 - action[i] )  * ( l_cp - ( e[i] * l_edge + ( 1 - e[i] ) * l_cp ) ) ) / S[i]\n",
    "\n",
    "        #self.Rh[i] = self.Rh[i] + self.Ro + self.Rl\n",
    "\n",
    "        return  self.Rh+self.Ro+self.Rl\n",
    "\n",
    "    def selectAction(self,env,uit):\n",
    "\n",
    "        self.lastAction = self.action\n",
    "        self.lastp = self.p\n",
    "        self.lastr = self.r\n",
    "\n",
    "        self.updateViewContent(uit[1])\n",
    "        self.r , self.p , self.e, self.S, self.l_edge, self.l_cp = env.getStatus()\n",
    "        \n",
    "        self.reward = self.getReward(self.lastr[self.u],self.lastp,self.r[self.u],self.p,self.W[-1],self.lastAction,self.S,self.Bu,self.l_edge,self.l_cp,self.e)\n",
    "        \n",
    "        self.action = torch.zeros(size=(env.contentNum,),dtype=int)\n",
    "        self.action[self.W[-1]] = 1\n",
    "\n",
    "        env.updateEnv(self.u,self.action.numpy(),uit[2])\n",
    "\n",
    "        return self.action"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "num_episodes = 1\n",
    "TARGET_UPDATE = 1\n",
    "bestReward =  float(\"-inf\")\n",
    "\n",
    "env = ENV(userNum,contentNum)\n",
    "UEs = {}\n",
    "sumReward = np.zeros(3)\n",
    "loss = 0\n",
    "UEHit = np.zeros(userNum)\n",
    "edgeHit = 0\n",
    "\n",
    "rewardPara = {\"alpha\":1,\"betao\":0.5,\"betal\":0.5}\n",
    "\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    for index,trace in trainUIT.iterrows():\n",
    "        uit = trace.to_numpy()\n",
    "        if uit[0] not in UEs:\n",
    "            UEs[uit[0]] = UE_None(uit[0],env,rewardPara)\n",
    "\n",
    "        ue = UEs[uit[0]]\n",
    "        \n",
    "        actionIndex = np.argwhere(ue.lastAction)\n",
    "        if uit[1] in actionIndex:\n",
    "            UEHit[uit[0]] += 1\n",
    "        elif uit[1] in env.pipe.keys():\n",
    "            edgeHit += 1\n",
    "\n",
    "        ue.selectAction(env,uit)\n",
    "\n",
    "        sumReward[0] += float(ue.Rh)\n",
    "        sumReward[1] += float(ue.Rl)\n",
    "        sumReward[2] += float(ue.Ro)\n",
    "\n",
    "        if index % 10000 == 0 :\n",
    "            psi = 0\n",
    "            p = torch.from_numpy(env.p)\n",
    "            for u in UEs:\n",
    "                psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "            print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "            print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "            print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "            print()\n",
    "            sumHitrate[int(index // 10000)]   = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "            UEHitrate [int(index // 10000)]   = round(UEHit.sum()/(index+1),5)\n",
    "            edgeHitrate [int(index // 10000)] = round(edgeHit/(index+1),5)\n",
    "\n",
    "    psi = 0\n",
    "    p = torch.from_numpy(env.p)\n",
    "    for u in UEs:\n",
    "        psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "    print()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "    print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "    print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Time: Wed Sep 15 22:04:35 2021 Episode: 0   Index: 0   Loss: 0.0 --\n",
      "Reward: [0. 0. 0.] total reward: 0.0\n",
      "UEHitrate: 0.0  edgeHitrate 0.0 sumHitrate 0.0  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:04:45 2021 Episode: 0   Index: 10000   Loss: 0.0 --\n",
      "Reward: [0.10938 0.1794  0.00074] total reward: 0.28952\n",
      "UEHitrate: 0.0018  edgeHitrate 0.39936 sumHitrate 0.40116  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:04:55 2021 Episode: 0   Index: 20000   Loss: 0.0 --\n",
      "Reward: [0.03867 0.18685 0.00087] total reward: 0.22639\n",
      "UEHitrate: 0.00195  edgeHitrate 0.41593 sumHitrate 0.41788  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:05:05 2021 Episode: 0   Index: 30000   Loss: 0.0 --\n",
      "Reward: [0.01672 0.19601 0.00083] total reward: 0.21356\n",
      "UEHitrate: 0.0024  edgeHitrate 0.43615 sumHitrate 0.43855  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:05:15 2021 Episode: 0   Index: 40000   Loss: 0.0 --\n",
      "Reward: [0.01123 0.19757 0.00101] total reward: 0.20981\n",
      "UEHitrate: 0.00247  edgeHitrate 0.43974 sumHitrate 0.44221  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:05:25 2021 Episode: 0   Index: 50000   Loss: 0.0 --\n",
      "Reward: [0.0048  0.19843 0.00096] total reward: 0.20419\n",
      "UEHitrate: 0.00246  edgeHitrate 0.44157 sumHitrate 0.44403  privacy: 1.0\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "--Time: Wed Sep 15 22:05:32 2021 Episode: 0   Index: 56743   Loss: 0.0 --\n",
      "Reward: [-0.00056  0.19738  0.00101] total reward: 0.19783\n",
      "UEHitrate: 0.00252  edgeHitrate 0.43924 sumHitrate 0.44176  privacy: 1.0\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "num_episodes = 1\n",
    "TARGET_UPDATE = 1\n",
    "bestReward =  float(\"-inf\")\n",
    "\n",
    "env = ENV(userNum,contentNum)\n",
    "UEs = {}\n",
    "sumReward = np.zeros(3)\n",
    "loss = 0\n",
    "UEHit = np.zeros(userNum)\n",
    "edgeHit = 0\n",
    "\n",
    "rewardPara = {\"alpha\":1,\"betao\":0.5,\"betal\":0.5}\n",
    "\n",
    "sumHitrate = np.zeros(10)\n",
    "UEHitrate = np.zeros(10)\n",
    "edgeHitrate = np.zeros(10)\n",
    "privacyReduction = np.zeros(10)\n",
    "\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "\n",
    "    for index,trace in UIT.iterrows():\n",
    "        uit = trace.to_numpy()\n",
    "        if uit[0] not in UEs:\n",
    "            UEs[uit[0]] = UE_None(uit[0],env,rewardPara)\n",
    "\n",
    "        ue = UEs[uit[0]]\n",
    "        \n",
    "        actionIndex = np.argwhere(ue.lastAction)\n",
    "        if uit[1] in actionIndex:\n",
    "            UEHit[uit[0]] += 1\n",
    "        elif uit[1] in env.pipe.keys():\n",
    "            edgeHit += 1\n",
    "\n",
    "        ue.selectAction(env,uit)\n",
    "\n",
    "        sumReward[0] += float(ue.Rh)\n",
    "        sumReward[1] += float(ue.Rl)\n",
    "        sumReward[2] += float(ue.Ro)\n",
    "\n",
    "        if index % 10000 == 0 :\n",
    "            psi = 0\n",
    "            p = torch.from_numpy(env.p)\n",
    "            for u in UEs:\n",
    "                psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "            print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "            print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "            print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "            print()\n",
    "            sumHitrate[int(index // 10000)]   = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "            UEHitrate [int(index // 10000)]   = round(UEHit.sum()/(index+1),5)\n",
    "            edgeHitrate [int(index // 10000)] = round(edgeHit/(index+1),5)\n",
    "            privacyReduction [int(index // 10000)] = round(float(psi)/len(UEs),5)\n",
    "    psi = 0\n",
    "    p = torch.from_numpy(env.p)\n",
    "    for u in UEs:\n",
    "        psi += torch.log(UEs[u].r[u] * p + (1-UEs[u].r[u]) * (1-p)).sum() / torch.log(UEs[u].v * p + (1-UEs[u].v) * (1-p)).sum()\n",
    "    print()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"--Time:\",time.asctime( time.localtime(time.time())),\"Episode:\",i_episode,\"  Index:\",index,\"  Loss:\",round(loss/(index+1),5),\"--\")\n",
    "    print(\"Reward:\",np.around(sumReward/(index+1),5),\"total reward:\",round(sumReward.sum()/(index+1),5))\n",
    "    print(\"UEHitrate:\",round(UEHit.sum()/(index+1),5),\" edgeHitrate\",round(edgeHit/(index+1),5),\"sumHitrate\",round((edgeHit+UEHit.sum())/(index+1),5),\" privacy:\",round(float(psi)/len(UEs),5))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    sumHitrate [int(round(index / 10000,0))]  = round((edgeHit+UEHit.sum())/(index+1),5)\n",
    "    UEHitrate  [int(round(index / 10000,0))]  = round(UEHit.sum()/(index+1),5)\n",
    "    edgeHitrate[int(round(index / 10000,0))]  = round(edgeHit/(index+1),5)\n",
    "    privacyReduction [int(round(index / 10000,0))] = round(float(psi)/len(UEs),5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--Time: Wed Sep 15 22:59:36 2021 Episode: 0   Index: 0   Loss: 0.0 --\n",
      "Reward: [0. 0. 0.] total reward: 0.0\n",
      "UEHitrate: 0.0  edgeHitrate 0.0 sumHitrate 0.0  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:59:47 2021 Episode: 0   Index: 10000   Loss: 0.0 --\n",
      "Reward: [0.10938 0.1794  0.00074] total reward: 0.28952\n",
      "UEHitrate: 0.0018  edgeHitrate 0.39936 sumHitrate 0.40116  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 22:59:58 2021 Episode: 0   Index: 20000   Loss: 0.0 --\n",
      "Reward: [0.03867 0.18685 0.00087] total reward: 0.22639\n",
      "UEHitrate: 0.00195  edgeHitrate 0.41593 sumHitrate 0.41788  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:09 2021 Episode: 0   Index: 30000   Loss: 0.0 --\n",
      "Reward: [0.01672 0.19601 0.00083] total reward: 0.21356\n",
      "UEHitrate: 0.0024  edgeHitrate 0.43615 sumHitrate 0.43855  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:20 2021 Episode: 0   Index: 40000   Loss: 0.0 --\n",
      "Reward: [0.01123 0.19757 0.00101] total reward: 0.20981\n",
      "UEHitrate: 0.00247  edgeHitrate 0.43974 sumHitrate 0.44221  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:31 2021 Episode: 0   Index: 50000   Loss: 0.0 --\n",
      "Reward: [0.0048  0.19843 0.00096] total reward: 0.20419\n",
      "UEHitrate: 0.00246  edgeHitrate 0.44157 sumHitrate 0.44403  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:42 2021 Episode: 0   Index: 60000   Loss: 0.0 --\n",
      "Reward: [-0.00059  0.197    0.00102] total reward: 0.19742\n",
      "UEHitrate: 0.00258  edgeHitrate 0.43834 sumHitrate 0.44093  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:00:53 2021 Episode: 0   Index: 70000   Loss: 0.0 --\n",
      "Reward: [-0.00434  0.19787  0.00103] total reward: 0.19456\n",
      "UEHitrate: 0.0028  edgeHitrate 0.44025 sumHitrate 0.44305  privacy: 1.0\n",
      "\n",
      "--Time: Wed Sep 15 23:01:03 2021 Episode: 0   Index: 80000   Loss: 0.0 --\n",
      "Reward: [-0.0076   0.19829  0.001  ] total reward: 0.1917\n",
      "UEHitrate: 0.00297  edgeHitrate 0.44133 sumHitrate 0.44431  privacy: 1.0\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "--Time: Wed Sep 15 23:01:14 2021 Episode: 0   Index: 89292   Loss: 0.0 --\n",
      "Reward: [-0.00976  0.20089  0.00102] total reward: 0.19215\n",
      "UEHitrate: 0.00298  edgeHitrate 0.44711 sumHitrate 0.45009  privacy: 1.0\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "sumHitrate, UEHitrate, edgeHitrate"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.     , 0.40116, 0.41788, 0.43855, 0.44221, 0.44403, 0.44093,\n",
       "        0.44305, 0.44431, 0.45009]),\n",
       " array([0.     , 0.0018 , 0.00195, 0.0024 , 0.00247, 0.00246, 0.00258,\n",
       "        0.0028 , 0.00297, 0.00298]),\n",
       " array([0.     , 0.39936, 0.41593, 0.43615, 0.43974, 0.44157, 0.43834,\n",
       "        0.44025, 0.44133, 0.44711]))"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "privacyReduction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53e075add4fc865efaed3001cae69f5b66291fd877e6c0fafb5013552ba051ca"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}